{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.cross_validation import train_test_split, cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from copy import copy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from math import sqrt\n",
    "import xgboost as xgb\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Несколько полезных функций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from .dat to pandas.DataFrame\n",
    "def get_data(filename):\n",
    "    f = open(filename, 'r')\n",
    "    array = []\n",
    "    names_of_columns_was_read = False\n",
    "    for line in f:\n",
    "        values = line.split(',')\n",
    "        values[-1] = values[-1][:-1]\n",
    "        if names_of_columns_was_read is False:\n",
    "            for i in xrange(1, len(values)):\n",
    "                values[i] = values[i][1:]\n",
    "            names_of_columns_was_read = True\n",
    "        else:\n",
    "            for i in xrange(len(values)):\n",
    "                if values[i] == '?':\n",
    "                    values[i] = np.nan\n",
    "                elif '.' in values[i]:\n",
    "                    values[i] = float(values[i])\n",
    "                elif values[i].isdigit():\n",
    "                    values[i] = int(values[i])\n",
    "        array.append(values)\n",
    "\n",
    "    data = pd.DataFrame(array[1:], columns=array[0])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#функция, делающая различные замены пропусков\n",
    "def imputMissingValues(X, Y):\n",
    "    X_columns = X.columns\n",
    "    #замена 1: случайное значение\n",
    "\n",
    "    X_random = X.copy()\n",
    "    nan_values = X.isnull()\n",
    "    for column_name in X_columns:\n",
    "        indices = list(nan_values[nan_values[column_name] == True].index.values)\n",
    "        for i in indices:\n",
    "            X_random.set_value(i, column_name, list(X[column_name].dropna().sample(random_state=42))[0])\n",
    "\n",
    "    #замена 2: среднее\n",
    "\n",
    "    X_mean = X.fillna(X.mean())\n",
    "\n",
    "    #замена 3: медиана\n",
    "\n",
    "    X_median = X.fillna(X.median())\n",
    "\n",
    "    #замена 4: мода\n",
    "\n",
    "    X_mode = X.fillna(X.mode().iloc[0])\n",
    "\n",
    "    #разбиение выборки по классам\n",
    "    values_of_Y = Y.value_counts()\n",
    "    classes = values_of_Y.index.values.tolist()\n",
    "    classes_dataframes = {}\n",
    "    for class_value in classes:\n",
    "        classes_dataframes[class_value] = data[data[columns[-1]] == class_value][X_columns]\n",
    "\n",
    "    #замена 5: среднее по классу\n",
    "\n",
    "    X_class_mean = X.copy()\n",
    "    for column_name in X_columns:\n",
    "        values_to_set = {}\n",
    "        for class_value in classes:\n",
    "            class_mean = classes_dataframes[class_value][column_name].dropna().mean()\n",
    "            if class_mean != np.nan: #случай когда все сэмплы со значением класса пустые\n",
    "                values_to_set[class_value] = class_mean\n",
    "\n",
    "        indices = list(nan_values[nan_values[column_name] == True].index.values)\n",
    "        for i in indices:\n",
    "            class_value = Y.loc[i]\n",
    "            if class_value in values_to_set.keys():\n",
    "                X_class_mean.set_value(i, column_name, values_to_set[class_value])\n",
    "\n",
    "    #замена 3: медиана по классу\n",
    "\n",
    "    X_class_median = X.copy()\n",
    "    for column_name in X_columns:\n",
    "        values_to_set = {}\n",
    "        for class_value in classes:\n",
    "            class_median = classes_dataframes[class_value][column_name].dropna().median()\n",
    "            if class_median != np.nan:\n",
    "                values_to_set[class_value] = classes_dataframes[class_value][column_name].dropna().median()\n",
    "\n",
    "        indices = list(nan_values[nan_values[column_name] == True].index.values)\n",
    "        for i in indices:\n",
    "            class_value = Y.loc[i]\n",
    "            if class_value in values_to_set.keys():\n",
    "                X_class_median.set_value(i, column_name, values_to_set[class_value])\n",
    "\n",
    "    #замена 4: мода по классу\n",
    "    #FIXME значение в случае отсутствия моды по классу (сейчас такие случаи просто игнорируются) \n",
    "\n",
    "    X_class_mode = X.copy()\n",
    "    for column_name in X_columns:\n",
    "        values_to_set = {}\n",
    "        for class_value in classes:\n",
    "            #values_to_set[class_value] = classes_dataframes[class_value][column_name].dropna().mode().ix[0, :]\n",
    "            class_mode = classes_dataframes[class_value][column_name].dropna().mode()\n",
    "            if class_mode.empty == False:\n",
    "                values_to_set[class_value] = class_mode.iloc[0]\n",
    "\n",
    "        indices = list(nan_values[nan_values[column_name] == True].index.values)\n",
    "        for i in indices:\n",
    "            class_value = Y.loc[i]\n",
    "            if class_value in values_to_set.keys():\n",
    "                X_class_mode.set_value(i, column_name, values_to_set[class_value])\n",
    "            \n",
    "    return (X_random, X_mean, X_median, X_mode, X_class_mean, X_class_median, X_class_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#функция для отделения классифицируемых признаков от регрессируемых :) (эвристическая - если меньше \n",
    "#max_number_of_values_per_class возможных значений признака, то он признается классифицируемым)\n",
    "def devide_features_to_classifiable_and_regressiable(df, max_number_of_values_per_class):\n",
    "    columns = list(df.columns.values)\n",
    "    devided_features = {'class':[], 'regr':[]}\n",
    "    for column in columns:\n",
    "        if len(df[column].value_counts().index) < max_number_of_values_per_class:\n",
    "            devided_features['class'].append(column)\n",
    "        else:\n",
    "            devided_features['regr'].append(column)\n",
    "    return devided_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#разбиение выборки\n",
    "def get_X_and_y_by_column_name(X, current_X_columns, column_name):\n",
    "    current_X = X[current_X_columns].dropna()\n",
    "    current_X_indices = list(current_X.index.values)\n",
    "    \n",
    "    current_y = X[column_name]\n",
    "    current_y_nan_values = current_y.isnull()\n",
    "    \n",
    "    y_train = pd.Series()\n",
    "    X_train = pd.DataFrame(columns=current_X_columns)\n",
    "    X_test = pd.DataFrame(columns=current_X_columns)\n",
    "    for index in current_X_indices:\n",
    "        if current_y_nan_values.loc[index] == True:\n",
    "            X_test.loc[index] = list(current_X.loc[index])\n",
    "        else:\n",
    "            y_train.set_value(index, current_y.loc[index])\n",
    "            X_train.loc[index] = list(current_X.loc[index])\n",
    "            \n",
    "    return (current_X, X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "#разбиение выборки с заполнением пустых значений на обучающей части выборки средним\n",
    "def get_X_and_y_by_column_name_with_imputs(X, current_X_columns, column_name):\n",
    "    current_X = pd.DataFrame(Imputer(strategy='median').fit_transform(X[current_X_columns]), columns=current_X_columns)\n",
    "    \n",
    "    current_y_nan_values = X[column_name].isnull()\n",
    "    \n",
    "    y_train = X[column_name][current_y_nan_values == False]\n",
    "    X_train = current_X[current_X_columns][current_y_nan_values == False]\n",
    "    X_test = current_X[current_X_columns][current_y_nan_values == True]\n",
    "            \n",
    "    return (current_X, X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#подогнать y под корректные значения для PyBrain классификатора\n",
    "def fit_y(y):\n",
    "    unique_values = list(y.unique())\n",
    "    \n",
    "    values_map = {}\n",
    "    for index in xrange(len(unique_values)):\n",
    "        values_map[unique_values[index]] = index\n",
    "        \n",
    "    fitted_y = pd.Series()\n",
    "    for index in y.index:\n",
    "        fitted_y.set_value(index, values_map[y.loc[index]])\n",
    "        \n",
    "    return (fitted_y, values_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#дешифратор для предыдущей функции\n",
    "def decrypt_y(y_fitted, values_map):\n",
    "    decrypt_map = {}\n",
    "    for key, value in values_map.iteritems():\n",
    "        decrypt_map[value] = key\n",
    "    \n",
    "    y = pd.Series()\n",
    "    for index in y_fitted.index:\n",
    "        y.set_value(index, decrypt_map[y_fitted.loc[index]])\n",
    "        \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#функция, вычисляющая метрику\n",
    "def closest_fit_metric(a, b, **kwargs):\n",
    "    max_min_differences = []\n",
    "    for key, value in kwargs.items():\n",
    "        if key == 'max_min_differences':\n",
    "            max_min_differences = value\n",
    "        else:\n",
    "            raise ValueError('Unexpeceted parameter ' + key)\n",
    "    \n",
    "    if max_min_differences == 0.0:\n",
    "        raise ValueError('max_min_differences should be intialized to use this close-fit metric')\n",
    "            \n",
    "    d = len(a)\n",
    "    dist = 0.0\n",
    "    for i in xrange(d):\n",
    "        if a[i] != b[i]:\n",
    "            data_type = type(a[i])\n",
    "            if data_type == np.int64 or data_type == np.float64:\n",
    "                dist += abs(a[i] - b[i])/max_min_differences[i]\n",
    "            else:\n",
    "                dist += 1.0\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def sort_and_print_results(results):\n",
    "    results_sorted_by_maxAcc = sorted(results.iteritems(), key=operator.itemgetter(1), reverse=True)\n",
    "    for item in results_sorted_by_maxAcc:\n",
    "        print item[1], item[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#создадим массив из разниц максимального и минимального значения для признака\n",
    "\n",
    "def get_max_min_differences_array_from_data(X):\n",
    "    max_values = [X.iloc[0][j] for j in xrange(len(X.columns))]\n",
    "    min_values = [value for value in max_values]\n",
    "    \n",
    "    for sample_index in xrange(1, len(X.index)):\n",
    "        for column_index in xrange(len(X.columns)):\n",
    "            cell_value = X.iloc[sample_index][column_index]\n",
    "            \n",
    "            if type(cell_value) == np.int64 or type(cell_value) == np.float64:\n",
    "                if cell_value > max_values[column_index]:\n",
    "                    max_values[column_index] = cell_value\n",
    "\n",
    "                elif cell_value < min_values[column_index]:\n",
    "                    min_values[column_index] = cell_value\n",
    "                            \n",
    "    max_min_differences = []\n",
    "    for index in xrange(len(max_values)):\n",
    "        if type(max_values[index]) == np.int64 or type(max_values[index]) == np.float64:\n",
    "            max_min_differences.append(max_values[index] - min_values[index])\n",
    "        else:\n",
    "            max_min_differences.append(0.0)\n",
    "    \n",
    "    return max_min_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neighbors(X, y, results, method_name, min_neigh_num, max_neigh_num):\n",
    "    max_acc = 0\n",
    "    best_neigh = 0\n",
    "    epsilon = 0.005\n",
    "    \n",
    "    for neighbors_num in xrange(min_neigh_num, max_neigh_num):\n",
    "        knn = KNeighborsClassifier(metric = 'manhattan', n_neighbors = neighbors_num)\n",
    "\n",
    "        X_scaled = StandardScaler().fit_transform(X)\n",
    "        acc_score = cross_val_score(knn, X_scaled, y, cv=5)\n",
    "        mean_acc_score = acc_score.mean()\n",
    "\n",
    "        if mean_acc_score > max_acc + epsilon:\n",
    "            max_acc = mean_acc_score\n",
    "            best_neigh = neighbors_num\n",
    "            \n",
    "    results[method_name] = (max_acc, best_neigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rep.estimators.pybrain import PyBrainClassifier\n",
    "\n",
    "def pybrain_classification(X, y, results, method_name):\n",
    "    y_fitted, values_map = fit_y(y)\n",
    "    \n",
    "    pb = PyBrainClassifier(layers=[10], epochs=10, verbose=False)\n",
    "    \n",
    "    acc_score = cross_val_score(pb, X, y_fitted, cv=5)\n",
    "    results[method_name] = acc_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "def SVMClassification(X, y, results, method_name):\n",
    "    scaled_X = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    svc_acc = cross_val_score(svm.SVC(), scaled_X, y, cv=5).mean()\n",
    "    nusvc_acc = cross_val_score(svm.NuSVC(), scaled_X, y, cv=5).mean()\n",
    "    linearsvc_acc = cross_val_score(svm.LinearSVC(), scaled_X, y, cv=5).mean()\n",
    "    \n",
    "    acc_map = {svc_acc: 'SVC', nusvc_acc: 'NuSVC', linearsvc_acc: 'LinearSVC'}\n",
    "    max_acc = max(svc_acc, nusvc_acc, linearsvc_acc)\n",
    "    \n",
    "    results[method_name] = (max_acc, acc_map[max_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SVMMultiClassification(X, y, results, method_name):\n",
    "    scaled_X = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    svc_acc = cross_val_score(svm.SVC(decision_function_shape='ovo'), scaled_X, y, cv=5).mean()\n",
    "    nusvc_acc = cross_val_score(svm.NuSVC(decision_function_shape='ovo'), scaled_X, y, cv=5).mean()\n",
    "    linearsvc_acc = cross_val_score(svm.LinearSVC(), scaled_X, y, cv=5).mean()\n",
    "    \n",
    "    acc_map = {svc_acc: 'SVC', nusvc_acc: 'NuSVC', linearsvc_acc: 'LinearSVC'}\n",
    "    max_acc = max(svc_acc, nusvc_acc, linearsvc_acc)\n",
    "    \n",
    "    results[method_name] = (max_acc, acc_map[max_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as lr\n",
    "\n",
    "def logisticRegClassification(X, y, results, method_name):\n",
    "    scaled_X = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    newton_acc = cross_val_score(lr(solver='newton-cg'), scaled_X, y, cv=5).mean()\n",
    "    lbfgs_acc = cross_val_score(lr(solver='lbfgs'), scaled_X, y, cv=5).mean()\n",
    "    liblinear_acc = cross_val_score(lr(solver='liblinear'), scaled_X, y, cv=5).mean()\n",
    "    sag_acc = cross_val_score(lr(solver='sag'), scaled_X, y, cv=5).mean()\n",
    "    \n",
    "    acc_map = {newton_acc: 'newton-cg', lbfgs_acc: 'lbfgs', liblinear_acc: 'liblinear', sag_acc: 'sag'}\n",
    "    max_acc = max(newton_acc, lbfgs_acc, liblinear_acc, sag_acc)\n",
    "    \n",
    "    results[method_name] = (max_acc, acc_map[max_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_forest_classification(X, y, results, method_name, min_trees_num, max_trees_num, step):\n",
    "    \n",
    "    max_acc_score = 0.0\n",
    "    best_trees_num = min_trees_num\n",
    "    epsilon = 0.005\n",
    "    \n",
    "    trees_numbers = [(min_trees_num + 3*i) for i in xrange((max_trees_num - min_trees_num)/3)]\n",
    "    \n",
    "    for trees_num in trees_numbers:\n",
    "        \n",
    "        rf = RandomForestClassifier(n_estimators=trees_num)\n",
    "        \n",
    "        X_scaled = StandardScaler().fit_transform(X)\n",
    "        \n",
    "        acc_score = cross_val_score(rf, X_scaled, y, cv=5)\n",
    "        acc_score = acc_score.mean()\n",
    "        \n",
    "        if acc_score > max_acc_score + epsilon:\n",
    "            best_trees_num = trees_num\n",
    "            max_acc_score = acc_score\n",
    "            \n",
    "    results[method_name] = (max_acc_score, best_trees_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def NBClassification(X, y, results, method_name):\n",
    "    scaled_X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    results[method_name] = cross_val_score(GaussianNB(), scaled_X, y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNumAndCatfeatures(X):\n",
    "    num_columns = []\n",
    "    cat_columns = []\n",
    "    \n",
    "    for column in X.columns:\n",
    "        if type(X[column].dropna().iloc[0]) == str:\n",
    "            cat_columns.append(column)\n",
    "        else:\n",
    "            num_columns.append(column)\n",
    "            \n",
    "    return (num_columns, cat_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#удалить пропуски и подсоединить таргет\n",
    "def dropnaAndAddTarget(X, y, y_column):\n",
    "\n",
    "    data = X.copy()\n",
    "    data[y_column] = y.copy()\n",
    "    \n",
    "    data = data.dropna()\n",
    "    \n",
    "    newX = data[X.columns]\n",
    "    newY = data[y_column]\n",
    "    \n",
    "    return (newX, newY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#собрать y по X\n",
    "def fitYtoX(X, Y):\n",
    "    y = pd.Series()\n",
    "    for index in list(X.index.values):\n",
    "        y.set_value(index, Y.loc[index])\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addImputedValuesToDF(df, values_to_set, indexes_of_imputed_values, column_name):\n",
    "    counter = 0\n",
    "    for index in indexes_of_imputed_values:\n",
    "        df.set_value(index, column_name, values_to_set[counter])\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Датасет mammographic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BI-RADS</th>\n",
       "      <th>Age</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Margin</th>\n",
       "      <th>Density</th>\n",
       "      <th>Severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BI-RADS  Age  Shape  Margin  Density  Severity\n",
       "0        5   67      3       5        3         1\n",
       "1        4   43      1       1      NaN         1\n",
       "2        5   58      4       5        3         1\n",
       "3        4   28      1       1        3         0\n",
       "4        5   74      1       5      NaN         1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_data('mammographic.dat')\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#выделям из данных Х и Y\n",
    "columns = list(data.columns.values)\n",
    "X_columns = columns[:-1]\n",
    "y_column = columns[-1]\n",
    "X = data[X_columns]\n",
    "Y = data[y_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02809573361082206"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getMissingDataRate(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#удалим объекты с пропущенными значениями\n",
    "\n",
    "data_deleted = data.dropna()\n",
    "X_deleted = data_deleted[columns[:-1]]\n",
    "y_deleted = data_deleted[columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class': ['BI-RADS', 'Shape', 'Margin', 'Density'], 'regr': ['Age']}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devided_features = devide_features_to_classifiable_and_regressiable(X, 10)\n",
    "devided_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Замены"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_random, X_mean, X_median, X_mode, X_class_mean, X_class_median, X_class_mode = imputMissingValues(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'copy_x': True,\n",
       " 'init': 'k-means++',\n",
       " 'max_iter': 300,\n",
       " 'n_clusters': 8,\n",
       " 'n_init': 10,\n",
       " 'n_jobs': 1,\n",
       " 'precompute_distances': 'auto',\n",
       " 'random_state': None,\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par = {}\n",
    "esr = KMeans(**par)\n",
    "#esr.set_params(**par)\n",
    "esr.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kmeans_imputer(n_clusters, df):\n",
    "    estr = KMeans(n_clusters=n_clusters, max_iter=300, n_init=100, init='k-means++', n_jobs=2, random_state=282)\n",
    "    clusters_pred = estr.fit_predict(Imputer().fit_transform(df))\n",
    "    cluster_centers = estr.cluster_centers_\n",
    "    \n",
    "    data_means2 = df.copy()\n",
    "    for index in range(data_means2.shape[0]):\n",
    "\n",
    "        row = data_means2.iloc[index].isnull()\n",
    "\n",
    "        if row.any():\n",
    "            for column_index in range(row.size):\n",
    "                if row.iloc[column_index] == True:\n",
    "\n",
    "                    data_means2.set_value(index, \n",
    "                                          data_means2.columns[column_index], \n",
    "                                          cluster_centers[clusters_pred[index], column_index])\n",
    "                    \n",
    "    return data_means2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BI-RADS</th>\n",
       "      <th>Age</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Margin</th>\n",
       "      <th>Density</th>\n",
       "      <th>Severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.875856</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>74</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.920818</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.404422</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>3.172676</td>\n",
       "      <td>3.404422</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.945397</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>57</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>2.809205</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BI-RADS  Age     Shape    Margin   Density  Severity\n",
       "0        5   67  3.000000  5.000000  3.000000         1\n",
       "1        4   43  1.000000  1.000000  2.875856         1\n",
       "2        5   58  4.000000  5.000000  3.000000         1\n",
       "3        4   28  1.000000  1.000000  3.000000         0\n",
       "4        5   74  1.000000  5.000000  2.920818         1\n",
       "5        4   65  1.000000  3.404422  3.000000         0\n",
       "6        4   70  3.172676  3.404422  3.000000         0\n",
       "7        5   42  1.000000  1.945397  3.000000         0\n",
       "8        5   57  1.000000  5.000000  3.000000         1\n",
       "9        5   60  2.809205  5.000000  1.000000         1"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_means3[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_means2 = kmeans_imputer(2, data)\n",
    "data_means3 = kmeans_imputer(3, data)\n",
    "data_means4 = kmeans_imputer(4, data)\n",
    "data_means5 = kmeans_imputer(5, data)\n",
    "data_means6 = kmeans_imputer(6, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.83560556994818658, 53) means5\n",
      "(0.834558506044905, 52) means6\n",
      "(0.83248167411070528, 18) deleted\n",
      "(0.83248056994818653, 48) means2\n",
      "(0.83144969775474953, 47) means4\n",
      "(0.82935556994818638, 49) means3\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "neighbors(X_deleted, y_deleted, results, 'deleted', 10, 70)\n",
    "neighbors(data_means2[data_means2.columns[:-1]], \n",
    "          data_means2[data_means2.columns[-1]], results, 'means2', 10, 70)\n",
    "neighbors(data_means3[data_means3.columns[:-1]], \n",
    "          data_means3[data_means3.columns[-1]], results, 'means3', 10, 70)\n",
    "neighbors(data_means4[data_means4.columns[:-1]], \n",
    "          data_means4[data_means4.columns[-1]], results, 'means4', 10, 70)\n",
    "neighbors(data_means5[data_means5.columns[:-1]], \n",
    "          data_means5[data_means5.columns[-1]], results, 'means5', 10, 70)\n",
    "neighbors(data_means6[data_means6.columns[:-1]], \n",
    "          data_means6[data_means6.columns[-1]], results, 'means6', 10, 70)\n",
    "sort_and_print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.84286485319516413, 25) class_median\n",
      "(0.83766191709844562, 46) class_mean\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "neighbors(X_class_mean, Y, results, 'class_mean', 10, 70)\n",
    "neighbors(X_class_median, Y, results, 'class_median', 10, 70)\n",
    "sort_and_print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    798\n",
       "2     59\n",
       "1     16\n",
       "4     12\n",
       "Name: Density, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Density'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 37.90241392,   1.95897431,  11.98785047,  11.83738734,\n",
       "         23.49281076],\n",
       "       [ 29.02241971,   8.48390893,  20.95267719,   3.6316995 ,\n",
       "         14.69320994],\n",
       "       [  1.64820393,  38.38073812,  51.03654541,  27.5122312 ,\n",
       "         15.81857689],\n",
       "       [ 27.96723108,   9.65370924,  22.07673047,   3.3201359 ,\n",
       "         13.69382536],\n",
       "       [ 46.79320695,  10.02879408,   3.81115277,  20.75163341,\n",
       "         32.39043714],\n",
       "       [ 12.77496467,  24.42509788,  37.06137199,  13.61933128,\n",
       "          2.52792766],\n",
       "       [  6.8702054 ,  30.35791162,  43.00515379,  19.50482375,\n",
       "          7.88016116],\n",
       "       [ 30.71466642,   6.86726434,  19.18849538,   5.20636839,\n",
       "         16.36835444],\n",
       "       [ 24.71722669,  12.66570918,  25.18005341,   3.06504183,\n",
       "         10.46366305],\n",
       "       [ 22.88362726,  14.34916199,  26.97456072,   3.81638403,\n",
       "          8.58519864]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estr.transform(data.dropna()[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.748063046545 33\n",
      "0.654197453942 14\n",
      "0.607098348041 70\n",
      "0.909677932509 10\n"
     ]
    }
   ],
   "source": [
    "#метод ближайших соседей\n",
    "#для начала пойдем самым простым путем - для обучения воспользуемся только полностью заполненными объектами\n",
    "\n",
    "X_knn = X.copy()\n",
    "\n",
    "for column_name in devided_features['class']:\n",
    "    current_X_columns = copy(devided_features['class'])\n",
    "    current_X_columns.remove(column_name)\n",
    "    \n",
    "    #обучение\n",
    "    current_y = X_deleted[column_name]\n",
    "    current_X = X_deleted[current_X_columns]\n",
    "    \n",
    "    max_acc = 0\n",
    "    best_neigh_num = 0\n",
    "    epsilon = 0.005\n",
    "\n",
    "    for neighbors_num in xrange(3, 100):\n",
    "        knn = KNeighborsClassifier(metric = 'manhattan', n_neighbors = neighbors_num)\n",
    "        #knn = KNeighborsClassifier(n_neighbors=neighbors_num)\n",
    "        X_scaled = StandardScaler().fit_transform(current_X)\n",
    "        mean_acc_score = cross_val_score(knn, X_scaled, current_y, cv=5).mean()\n",
    "\n",
    "        if mean_acc_score > max_acc + epsilon:\n",
    "            max_acc = mean_acc_score\n",
    "            best_neigh_num = neighbors_num\n",
    "\n",
    "    print max_acc, best_neigh_num\n",
    "    \n",
    "    current_X, X_train, y_train, X_test = get_X_and_y_by_column_name(X, current_X_columns, column_name)\n",
    "            \n",
    "    #применение knn\n",
    "    knn_for_missing_values = KNeighborsClassifier(metric = 'manhattan', n_neighbors=best_neigh_num)\n",
    "    scaler = StandardScaler().fit(current_X)\n",
    "    knn_for_missing_values.fit(scaler.transform(X_train), y_train)\n",
    "    y_test = knn_for_missing_values.predict(scaler.transform(X_test))\n",
    "    X_test_indices = list(X_test.index.values)\n",
    "    counter = 0\n",
    "    for index in X_test_indices:\n",
    "        X_knn.set_value(index, column_name, y_test[counter])\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI-RADS 0.733029349577 51\n",
      "Shape 0.619367737584 18\n",
      "Margin 0.628626117585 93\n",
      "Density 0.901733294968 9\n"
     ]
    }
   ],
   "source": [
    "#метод ближайших соседей\n",
    "\n",
    "X_knn1 = X.copy()\n",
    "\n",
    "for column_name in devided_features['class']:\n",
    "    current_X_columns = copy(list(X_knn1.columns))\n",
    "    current_X_columns.remove(column_name)\n",
    "    \n",
    "    #обучение\n",
    "    #current_y = X_deleted[column_name]\n",
    "    #current_X = X_deleted[current_X_columns]\n",
    "    \n",
    "    current_X, X_train, y_train, X_test = get_X_and_y_by_column_name_with_imputs(X_knn1, current_X_columns, column_name)\n",
    "    \n",
    "    max_acc = 0\n",
    "    best_neigh_num = 0\n",
    "    epsilon = 0.005\n",
    "\n",
    "    for neighbors_num in xrange(3, 100, 3):\n",
    "        knn = KNeighborsClassifier(metric = 'manhattan', n_neighbors = neighbors_num)\n",
    "        #knn = KNeighborsClassifier(n_neighbors=neighbors_num)\n",
    "        X_scaled = StandardScaler().fit_transform(X_train)\n",
    "        mean_acc_score = cross_val_score(knn, X_scaled, y_train, cv=5).mean()\n",
    "\n",
    "        if mean_acc_score > max_acc + epsilon:\n",
    "            max_acc = mean_acc_score\n",
    "            best_neigh_num = neighbors_num\n",
    "\n",
    "    print column_name, max_acc, best_neigh_num\n",
    "            \n",
    "    #применение knn\n",
    "    knn_for_missing_values = KNeighborsClassifier(metric = 'manhattan', n_neighbors=best_neigh_num)\n",
    "    scaler = StandardScaler().fit(current_X)\n",
    "    knn_for_missing_values.fit(scaler.transform(X_train), y_train)\n",
    "    y_test = knn_for_missing_values.predict(scaler.transform(X_test))\n",
    "    X_test_indices = list(X_test.index.values)\n",
    "    counter = 0\n",
    "    for index in X_test_indices:\n",
    "        X_knn1.set_value(index, column_name, y_test[counter])\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age 13.5277002918 90\n"
     ]
    }
   ],
   "source": [
    "#метод ближайших соседей регрессия\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "for column_name in devided_features['regr']:\n",
    "    current_X_columns = copy(list(X_knn1.columns))\n",
    "    current_X_columns.remove(column_name)\n",
    "    \n",
    "    #обучение\n",
    "    #current_y = X_deleted[column_name]\n",
    "    #current_X = X_deleted[current_X_columns]\n",
    "    \n",
    "    current_X, X_train, y_train, X_test = get_X_and_y_by_column_name_with_imputs(X_knn1, \n",
    "                                                                                 current_X_columns, \n",
    "                                                                                 column_name)\n",
    "    \n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X_train, y_train, test_size=0.33, random_state=22)\n",
    "    \n",
    "    min_mse = 0.0\n",
    "    best_neigh_num = 0\n",
    "    epsilon = 0.005\n",
    "\n",
    "    for neighbors_num in xrange(3, 100, 3):\n",
    "        knn = KNeighborsRegressor(n_neighbors = neighbors_num)\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_tr)\n",
    "        knn.fit(X_scaled, y_tr)\n",
    "        y_pred = knn.predict(scaler.transform(X_te))\n",
    "        \n",
    "        mse = sqrt(MSE(y_te, y_pred))\n",
    "        \n",
    "        if neighbors_num == 3:\n",
    "            min_mse = mse\n",
    "        elif mse < min_mse - epsilon:\n",
    "            min_mse = mse\n",
    "            best_neigh_num = neighbors_num\n",
    "\n",
    "    print column_name, min_mse, best_neigh_num\n",
    "            \n",
    "    #применение knn\n",
    "    knn_for_missing_values = KNeighborsRegressor(n_neighbors=best_neigh_num)\n",
    "    scaler = StandardScaler().fit(current_X)\n",
    "    knn_for_missing_values.fit(scaler.transform(X_train), y_train)\n",
    "    y_test = knn_for_missing_values.predict(scaler.transform(X_test))\n",
    "    X_test_indices = list(X_test.index.values)\n",
    "    counter = 0\n",
    "    for index in X_test_indices:\n",
    "        X_knn1.set_value(index, column_name, y_test[counter])\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#для X_knn соберем y_knn\n",
    "X_knn = X_knn.dropna()\n",
    "y_knn = pd.Series()\n",
    "for index in list(X_knn.index.values):\n",
    "    y_knn.set_value(index, Y.loc[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Closest_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.733615859342 8\n",
      "0.64458784512 13\n",
      "0.589089324433 39\n",
      "0.909677932509 10\n",
      "CPU times: user 9min 50s, sys: 192 ms, total: 9min 50s\n",
      "Wall time: 9min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_closest_fit = X.copy()\n",
    "\n",
    "max_min_differences = get_max_min_differences_array_from_data(X_deleted)\n",
    "\n",
    "for column_name in devided_features['class']:\n",
    "    current_X_columns = copy(devided_features['class'])\n",
    "    current_X_columns.remove(column_name)\n",
    "    \n",
    "    #обучение\n",
    "    current_y = X_deleted[column_name]\n",
    "    current_X = X_deleted[current_X_columns]\n",
    "    \n",
    "    max_acc = 0\n",
    "    best_neigh_num = 0\n",
    "    epsilon = 0.005\n",
    "    max_min_differences = get_max_min_differences_array_from_data(X_deleted)\n",
    "\n",
    "    for neighbors_num in xrange(3, 50):\n",
    "        knn = KNeighborsClassifier(n_neighbors=neighbors_num,\n",
    "                                   metric=closest_fit_metric,\n",
    "                                   metric_params={'max_min_differences':max_min_differences})\n",
    "        X_scaled = StandardScaler().fit_transform(current_X)\n",
    "        mean_acc_score = cross_val_score(knn, X_scaled, current_y, cv=5).mean()\n",
    "\n",
    "        if mean_acc_score > max_acc + epsilon:\n",
    "            max_acc = mean_acc_score\n",
    "            best_neigh_num = neighbors_num\n",
    "\n",
    "    print max_acc, best_neigh_num\n",
    "    \n",
    "    current_X, X_train, y_train, X_test = get_X_and_y_by_column_name(X, current_X_columns, column_name)\n",
    "            \n",
    "    max_min_differences = get_max_min_differences_array_from_data(current_X)\n",
    "            \n",
    "    #применение knn\n",
    "    knn_for_missing_values = KNeighborsClassifier(n_neighbors=best_neigh_num,\n",
    "                                                  metric=closest_fit_metric,\n",
    "                                                  metric_params={'max_min_differences':max_min_differences})\n",
    "    scaler = StandardScaler().fit(current_X)\n",
    "    knn_for_missing_values.fit(scaler.transform(X_train), y_train)\n",
    "    y_test = knn_for_missing_values.predict(scaler.transform(X_test))\n",
    "    X_test_indices = list(X_test.index.values)\n",
    "    counter = 0\n",
    "    for index in X_test_indices:\n",
    "        X_closest_fit.set_value(index, column_name, y_test[counter])\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#для X_closest_fit соберем y_closest_fit\n",
    "X_closest_fit = X_closest_fit.dropna()\n",
    "y_closest_fit = fitYtoX(X_closest_fit, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###PyBrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.6 s, sys: 12 ms, total: 37.6 s\n",
      "Wall time: 37.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_pybrain = X.copy()\n",
    "\n",
    "for column_name in devided_features['class']:\n",
    "    current_X_columns = copy(list(X_pybrain.columns))\n",
    "    current_X_columns.remove(column_name)\n",
    "    \n",
    "    current_X, X_train, y_train, X_test = get_X_and_y_by_column_name(X_pybrain, current_X_columns, column_name)\n",
    "    fitted_y, values_map = fit_y(y_train)\n",
    "    \n",
    "    pb_for_missing_values = PyBrainClassifier(layers=[10],\n",
    "                                              epochs=7,\n",
    "                                              verbose=False)\n",
    "    pb_for_missing_values.fit(X_train, fitted_y)\n",
    "    y_test_fitted = pb_for_missing_values.predict(X_test)\n",
    "    \n",
    "    y_test = decrypt_y(pd.Series(y_test_fitted), values_map)\n",
    "    X_test_indices = list(X_test.index.values)\n",
    "    counter = 0\n",
    "    for index in X_test_indices:\n",
    "        X_pybrain.set_value(index, column_name, y_test[counter])\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.9 s, sys: 12 ms, total: 13.9 s\n",
      "Wall time: 13.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#svm\n",
    "\n",
    "X_svm = X.copy()\n",
    "\n",
    "for column_name in devided_features['class']:\n",
    "    current_X_columns = list(X_svm.columns)\n",
    "    current_X_columns.remove(column_name)\n",
    "    \n",
    "    current_X, X_train, y_train, X_test = get_X_and_y_by_column_name(X_svm, current_X_columns, column_name)\n",
    "    \n",
    "    clf = svm.SVC()\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    clf.fit(scaler.transform(X_train), y_train)\n",
    "    y_test = clf.predict(scaler.transform(X_test))\n",
    "    \n",
    "    addImputedValuesToDF(X_svm, y_test, list(X_test.index.values), column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.77 s, sys: 8 ms, total: 3.78 s\n",
      "Wall time: 3.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#svm\n",
    "for column_name in devided_features['regr']:\n",
    "    current_X_columns = list(X_svm.columns)\n",
    "    current_X_columns.remove(column_name)\n",
    "    \n",
    "    current_X, X_train, y_train, X_test = get_X_and_y_by_column_name(X_svm, current_X_columns, column_name)\n",
    "    \n",
    "    clf = svm.SVR()\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    clf.fit(scaler.transform(X_train), y_train)\n",
    "    y_test = clf.predict(scaler.transform(X_test))\n",
    "    \n",
    "    addImputedValuesToDF(X_svm, y_test, list(X_test.index.values), column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#для X_svm соберем y_svm\n",
    "X_svm = X_svm.dropna()\n",
    "y_svm = fitYtoX(X_svm, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.5 s, sys: 0 ns, total: 15.5 s\n",
      "Wall time: 15.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#linear_regression\n",
    "\n",
    "X_lr = X.copy()\n",
    "\n",
    "for column_name in devided_features['class']:\n",
    "    current_X_columns = list(X_lr.columns)\n",
    "    current_X_columns.remove(column_name)\n",
    "    \n",
    "    current_X, X_train, y_train, X_test = get_X_and_y_by_column_name(X_lr, current_X_columns, column_name)\n",
    "    \n",
    "    results = {}\n",
    "    logisticRegClassification(X_train, y_train, results, 'lr')\n",
    "    \n",
    "    clf = lr(solver=results['lr'][1])\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    clf.fit(scaler.transform(X_train), y_train)\n",
    "    y_test = clf.predict(scaler.transform(X_test))\n",
    "    \n",
    "    addImputedValuesToDF(X_lr, y_test, list(X_test.index.values), column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyamana/rep/local/lib/python2.7/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "for column_name in devided_features['regr']:\n",
    "    current_X_columns = list(X_lr.columns)\n",
    "    current_X_columns.remove(column_name)\n",
    "    \n",
    "    current_X, X_train, y_train, X_test = get_X_and_y_by_column_name(X_lr, current_X_columns, column_name)\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "                      \n",
    "    rgr = lr(solver='sag').fit(scaler.transform(X_train), y_train)\n",
    "    y_pred = rgr.predict(scaler.transform(X_test))\n",
    "    \n",
    "    addImputedValuesToDF(X_lr, y_pred, list(X_test.index.values), column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BI-RADS</th>\n",
       "      <th>Age</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Margin</th>\n",
       "      <th>Density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     BI-RADS  Age  Shape  Margin  Density\n",
       "443        4  NaN      4       5        3\n",
       "453        5  NaN      4       4        3\n",
       "683        5  NaN      3       3        3\n",
       "884        5  NaN      4       4        3\n",
       "923        5  NaN      4       3        3"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[X['Age'].isnull() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BI-RADS</th>\n",
       "      <th>Age</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Margin</th>\n",
       "      <th>Density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     BI-RADS  Age  Shape  Margin  Density\n",
       "443        4   67      4       5        3\n",
       "453        5   67      4       4        3\n",
       "683        5   66      3       3        3\n",
       "884        5   67      4       4        3\n",
       "923        5   66      4       3        3"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_lr[X['Age'].isnull() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#для X_lr соберем y_lr\n",
    "X_lr = X_lr.dropna()\n",
    "y_lr = fitYtoX(X_lr, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.4 s, sys: 4 ms, total: 13.4 s\n",
      "Wall time: 13.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#naive_bayes\n",
    "\n",
    "X_nb = X.copy()\n",
    "\n",
    "for column_name in devided_features['class']:\n",
    "    current_X_columns = list(X_nb.columns)\n",
    "    current_X_columns.remove(column_name)\n",
    "    \n",
    "    current_X, X_train, y_train, X_test = get_X_and_y_by_column_name(X_nb, current_X_columns, column_name)\n",
    "    \n",
    "    clf = GaussianNB()\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    clf.fit(scaler.transform(X_train), y_train)\n",
    "    y_test = clf.predict(scaler.transform(X_test))\n",
    "    \n",
    "    addImputedValuesToDF(X_nb, y_test, list(X_test.index.values), column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#для X_nb соберем y_nb\n",
    "X_nb = X_nb.dropna()\n",
    "y_nb = fitYtoX(X_nb, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total error:  110.320670325\n",
      "Total error:  88.5754404951\n",
      "Total error:  88.7237514159\n",
      "Total error:  88.8077870056\n",
      "Total error:  87.2379428317\n",
      "Total error:  88.0693606476\n",
      "Total error:  85.9416885983\n",
      "Total error:  87.0316186863\n",
      "Total error:  87.4965161327\n",
      "Total error:  86.0934201281\n",
      "CPU times: user 11.1 s, sys: 16 ms, total: 11.1 s\n",
      "Wall time: 11.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from rep.estimators.pybrain import PyBrainRegressor\n",
    "\n",
    "for column_name in devided_features['regr']:\n",
    "    current_X_columns = copy(list(X_pybrain.columns))\n",
    "    current_X_columns.remove(column_name)\n",
    "    \n",
    "    current_X, X_train, y_train, X_test = get_X_and_y_by_column_name(X_pybrain, current_X_columns, column_name)\n",
    "    \n",
    "    rgr = PyBrainRegressor(layers=[10], epochs=10, verbose=True, max_epochs=30)\n",
    "    rgr.fit(X_train, y_train)\n",
    "    y_test = rgr.predict(X_test)\n",
    "    \n",
    "    X_test_indices = list(X_test.index.values)\n",
    "    counter = 0\n",
    "    for index in X_test_indices:\n",
    "        X_pybrain.set_value(index, column_name, y_test[counter])\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#для Y_pybrain соберем y_pybrain\n",
    "X_pybrain = X_pybrain.dropna()\n",
    "y_pybrain = fitYtoX(X_pybrain, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ls', 'lad', 'huber', 'quantile']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['ls', 'lad', 'huber', 'quantile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fromProbaToLabel(y):\n",
    "    for index in range(len(y)):\n",
    "        if y[index] < 0.5:\n",
    "            y[index] = 0\n",
    "        else:\n",
    "            y[index] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_mean, Y, test_size=0.33, random_state=2289)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_X_train = X_train.as_matrix()\n",
    "xgb_y_train = np.asarray(y_train)\n",
    "\n",
    "dtrain = xgb.DMatrix(xgb_X_train, label=xgb_y_train)\n",
    "\n",
    "xgb_X_test = X_test.as_matrix()\n",
    "\n",
    "dtest = xgb.DMatrix(xgb_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param = {'bst:max_depth':2, 'bst:eta':1, 'silent':1, 'objective':'binary:logistic'}\n",
    "param['nthread'] = 4\n",
    "param['eval_metric'] = 'error'\n",
    "\n",
    "num_round = 10\n",
    "bst = xgb.train(param.items(), dtrain, num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80503144654088055"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fromProbaToLabel(y_pred)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-error-mean</th>\n",
       "      <th>test-error-std</th>\n",
       "      <th>train-error-mean</th>\n",
       "      <th>train-error-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.384375</td>\n",
       "      <td>0.102030</td>\n",
       "      <td>0.367578</td>\n",
       "      <td>0.128185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.201563</td>\n",
       "      <td>0.018750</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.016453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.193750</td>\n",
       "      <td>0.027688</td>\n",
       "      <td>0.136328</td>\n",
       "      <td>0.010438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.182813</td>\n",
       "      <td>0.030698</td>\n",
       "      <td>0.128516</td>\n",
       "      <td>0.007851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.179688</td>\n",
       "      <td>0.033146</td>\n",
       "      <td>0.126172</td>\n",
       "      <td>0.005468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.181250</td>\n",
       "      <td>0.031792</td>\n",
       "      <td>0.122266</td>\n",
       "      <td>0.005327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.178125</td>\n",
       "      <td>0.037435</td>\n",
       "      <td>0.118359</td>\n",
       "      <td>0.004385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.037824</td>\n",
       "      <td>0.117188</td>\n",
       "      <td>0.006652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.037824</td>\n",
       "      <td>0.116406</td>\n",
       "      <td>0.007967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.176563</td>\n",
       "      <td>0.034799</td>\n",
       "      <td>0.114453</td>\n",
       "      <td>0.006371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test-error-mean  test-error-std  train-error-mean  train-error-std\n",
       "0         0.384375        0.102030          0.367578         0.128185\n",
       "1         0.201563        0.018750          0.150000         0.016453\n",
       "2         0.193750        0.027688          0.136328         0.010438\n",
       "3         0.182813        0.030698          0.128516         0.007851\n",
       "4         0.179688        0.033146          0.126172         0.005468\n",
       "5         0.181250        0.031792          0.122266         0.005327\n",
       "6         0.178125        0.037435          0.118359         0.004385\n",
       "7         0.175000        0.037824          0.117188         0.006652\n",
       "8         0.175000        0.037824          0.116406         0.007967\n",
       "9         0.176563        0.034799          0.114453         0.006371"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = xgb.cv(param.items(), dtrain, num_round, nfold=5, metrics={'error'})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_dmatrix(X, y):\n",
    "    #xgb_X = X.as_matrix()\n",
    "    xgb_y = np.asarray(y)\n",
    "\n",
    "    return xgb.DMatrix(X, label=xgb_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "for column_name in devided_features['class']:\n",
    "    current_X_columns = list(X.columns)\n",
    "    current_X_columns.remove(column_name)\n",
    "\n",
    "    current_X, X_train, y_train, _ = get_X_and_y_by_column_name_with_imputs(X,\n",
    "                                                                            current_X_columns,\n",
    "                                                                            column_name)\n",
    "    \n",
    "    scaler = StandardScaler().fit(current_X)\n",
    "    label_encoder = LabelEncoder().fit(X[column_name].dropna())\n",
    "    dtrain = self.get_dmatrix(scaler.transform(X_train), label_encoder.transform(y_train))\n",
    "\n",
    "    param = {'silent': 1, 'nthread': 4}\n",
    "    metric = ''\n",
    "    #how much classes do we classify?\n",
    "    num_class = y_train.value_counts().shape[0]\n",
    "    if num_class == 2:\n",
    "        param['objective'] = 'binary:logistic'\n",
    "        metric = 'error'\n",
    "    else:\n",
    "        metric = 'merror'\n",
    "        param['objective'] = 'multi:softmax'\n",
    "        param['num_class'] = num_class\n",
    "\n",
    "    #tune the best parameters\n",
    "    best_param = {'1-error': 0}\n",
    "    epsilon = 0.001\n",
    "    #these magic numbers used below probably should be changed\n",
    "    for eta in [0.3 + i*0.1 for i in range(8)]:\n",
    "        for max_depth in range(2, 11):\n",
    "            for num_round in range(10, 20):\n",
    "\n",
    "                param['bst:max_depth'] = max_depth\n",
    "                param['bst:eta'] = eta\n",
    "                errors_df = xgb.cv(param, dtrain, num_round, nfold=5, metrics={metric})\n",
    "\n",
    "                test_mean_error = errors_df.iloc[-1][0]\n",
    "                if test_mean_error > best_param['1-error'] + epsilon:\n",
    "                    best_param['1-error'] = test_mean_error\n",
    "                    best_param['max_depth'] = max_depth\n",
    "                    best_param['eta'] = eta\n",
    "                    best_param['num_round'] = num_round\n",
    "\n",
    "    if self.verbose == 1:\n",
    "        print(best_param)\n",
    "\n",
    "    param['bst:max_depth'] = best_param['max_depth']\n",
    "    param['bst:eta'] = best_param['eta']\n",
    "    self._classifiers[column_name] = xgb.train(param, dtrain, best_param['num_round'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   test-rmse-mean  test-rmse-std  train-rmse-mean  train-rmse-std\n",
      "0        0.174738       0.005455         0.170775        0.001456\n",
      "1        0.170062       0.004276         0.162780        0.001199\n",
      "2        0.167574       0.004064         0.158405        0.001146\n",
      "3        0.166828       0.003821         0.155800        0.001132\n",
      "4        0.166427       0.003254         0.153928        0.001331\n",
      "5        0.166957       0.003133         0.152782        0.001320\n",
      "6        0.167592       0.003025         0.151966        0.001307\n",
      "7        0.167807       0.003064         0.151350        0.001278\n",
      "8        0.168344       0.003188         0.150736        0.001412\n",
      "9        0.168852       0.003127         0.150439        0.001437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyamana/rep/local/lib/python2.7/site-packages/sklearn/preprocessing/data.py:324: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/home/tyamana/rep/local/lib/python2.7/site-packages/sklearn/preprocessing/data.py:359: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/home/tyamana/rep/local/lib/python2.7/site-packages/sklearn/preprocessing/data.py:377: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "for column_name in devided_features['class']:\n",
    "    current_X_columns = list(X.columns)\n",
    "    current_X_columns.remove(column_name)\n",
    "\n",
    "    current_X, X_train, y_train, _ = get_X_and_y_by_column_name_with_imputs(X,\n",
    "                                                                            current_X_columns,\n",
    "                                                                            column_name)\n",
    "\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X_train, y_train, test_size=0.33, random_state=22)\n",
    "    scaler = StandardScaler().fit(current_X)\n",
    "    scaler_\n",
    "    dtrain = get_dmatrix(scaler.transform(X_tr), MinMaxScaler().fit_transform(y_tr))\n",
    "\n",
    "    param = {'silent': 1, 'nthread': 4}\n",
    "    param['objective'] = 'reg:logistic'    \n",
    "    param['bst:max_depth'] = max_depth\n",
    "    param['bst:eta'] = eta\n",
    "\n",
    "    bst = xgb.train(param, dtrain, num_round)\n",
    "    y_pred = bst.predict(xgb.DMatrix(scaler.transform(X_te)))\n",
    "    \n",
    "    print y_pred\n",
    "    \n",
    "    print(sqrt(MSE(y_test, y_pred)))\n",
    "    \n",
    "    #errors_df = xgb.cv(param, dtrain, num_round, nfold=5, metrics={'rmse'})\n",
    "    #print(errors_df)\n",
    "\n",
    "    \"\"\"\n",
    "    #tune the best parameters\n",
    "    best_param = {'1-error': 0}\n",
    "    epsilon = 0.001\n",
    "    #these magic numbers used below probably should be changed\n",
    "    for eta in [0.3 + i*0.1 for i in range(8)]:\n",
    "        for max_depth in range(2, 11):\n",
    "            for num_round in range(10, 20):\n",
    "\n",
    "                param['bst:max_depth'] = max_depth\n",
    "                param['bst:eta'] = eta\n",
    "                \n",
    "                bst = xgb.train(param, dtrain, num_round)\n",
    "                \n",
    "                errors_df = xgb.cv(param, dtrain, num_round, nfold=5, metrics={'rmse'})\n",
    "\n",
    "                test_mean_error = errors_df.iloc[-1][0]\n",
    "                if test_mean_error > best_param['1-error'] + epsilon:\n",
    "                    best_param['1-error'] = test_mean_error\n",
    "                    best_param['max_depth'] = max_depth\n",
    "                    best_param['eta'] = eta\n",
    "                    best_param['num_round'] = num_round\n",
    "\n",
    "    print(best_param)\n",
    "\n",
    "    \"\"\"\n",
    "    #param['bst:max_depth'] = best_param['max_depth']\n",
    "    #param['bst:eta'] = best_param['eta']\n",
    "    #self._clr = xgb.train(param, dtrain, best_param['num_round'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "13.6074833102"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Применяем knn к обработанным данным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.84182318652849752, 25) class_mode\n",
      "(0.83766191709844562, 46) class_mean\n",
      "(0.83350064766839382, 20) knn_with_imputs\n",
      "(0.83248167411070528, 18) deleted\n",
      "(0.83246977547495682, 20) mode\n",
      "(0.83040263385146817, 25) mean\n",
      "(0.83039723661485321, 33) median\n",
      "(0.82935556994818638, 52) random\n",
      "(0.82608303956130036, 13) knn_for_miss_val\n",
      "CPU times: user 27.4 s, sys: 24 ms, total: 27.4 s\n",
      "Wall time: 27.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = {}\n",
    "\n",
    "neighbors(X_deleted, y_deleted, results, 'deleted', 10, 70)\n",
    "neighbors(X_random, Y, results, 'random', 10, 70)\n",
    "neighbors(X_mean, Y, results, 'mean', 10, 70)\n",
    "neighbors(X_median, Y, results, 'median', 10, 70)\n",
    "neighbors(X_mode, Y, results, 'mode', 10, 70)\n",
    "neighbors(X_class_mode, Y, results, 'class_mode', 10, 70)\n",
    "neighbors(X_class_mean, Y, results, 'class_mean', 10, 70)\n",
    "neighbors(X_knn, y_knn, results, 'knn_for_miss_val', 10, 70)\n",
    "neighbors(X_knn1, Y, results, 'knn_with_imputs', 10, 70)\n",
    "\n",
    "\n",
    "import operator\n",
    "results_sorted_by_maxAcc = sorted(results.iteritems(), key=operator.itemgetter(1), reverse=True)\n",
    "for item in results_sorted_by_maxAcc:\n",
    "    print item[1], item[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.84286485319516413, 25) class_median\n",
      "(0.84182318652849752, 25) class_mode\n",
      "(0.83766191709844562, 46) class_mean\n",
      "(0.83248167411070528, 18) deleted\n",
      "(0.83246977547495682, 20) mode\n",
      "(0.83040263385146817, 25) mean\n",
      "(0.83039723661485321, 33) median\n",
      "(0.82935556994818638, 52) random\n",
      "(0.82825695260477872, 54) closest_fit\n",
      "(0.82608891500195847, 10) nb\n",
      "(0.82608303956130036, 13) knn_for_miss_val\n",
      "(0.82490163442725117, 19) pybrain\n",
      "(0.82286892081422225, 13) svm\n",
      "(0.8228338577006179, 18) lr\n",
      "CPU times: user 42.3 s, sys: 7.98 ms, total: 42.3 s\n",
      "Wall time: 42.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = {}\n",
    "\n",
    "neighbors(X_deleted, y_deleted, results, 'deleted', 10, 70)\n",
    "neighbors(X_random, Y, results, 'random', 10, 70)\n",
    "neighbors(X_mean, Y, results, 'mean', 10, 70)\n",
    "neighbors(X_median, Y, results, 'median', 10, 70)\n",
    "neighbors(X_mode, Y, results, 'mode', 10, 70)\n",
    "neighbors(X_class_mode, Y, results, 'class_mode', 10, 70)\n",
    "neighbors(X_class_mean, Y, results, 'class_mean', 10, 70)\n",
    "neighbors(X_class_median, Y, results, 'class_median', 10, 70)\n",
    "neighbors(X_svm, y_svm, results, 'svm', 10, 70)\n",
    "neighbors(X_lr, y_lr, results, 'lr', 10, 70)\n",
    "neighbors(X_nb, y_nb, results, 'nb', 10, 70)\n",
    "neighbors(X_knn, y_knn, results, 'knn_for_miss_val', 10, 70)\n",
    "neighbors(X_closest_fit, y_closest_fit, results, 'closest_fit', 10, 70)\n",
    "neighbors(X_pybrain, y_pybrain, results, 'pybrain', 10, 70)\n",
    "\n",
    "import operator\n",
    "results_sorted_by_maxAcc = sorted(results.iteritems(), key=operator.itemgetter(1), reverse=True)\n",
    "for item in results_sorted_by_maxAcc:\n",
    "    print item[1], item[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.82595377851544838, 21)\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "neighbors(X_lr, y_lr, results, 'lr', 10, 70)\n",
    "print results['lr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Применим PyBrain к обработанным данным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.835743022125 nb\n",
      "0.835600172712 class_mean\n",
      "0.831428108808 random\n",
      "0.831417314335 class_median\n",
      "0.831406519862 class_mode\n",
      "0.831260872741 pybrain\n",
      "0.830386442142 mode\n",
      "0.830057344238 deleted\n",
      "0.826214378238 mean\n",
      "0.824984458512 knn_for_miss_val\n",
      "0.822804733204 closest_fit\n",
      "0.822798794587 svm\n",
      "0.822085492228 median\n",
      "0.819543989993 lr\n",
      "CPU times: user 7min 35s, sys: 72 ms, total: 7min 35s\n",
      "Wall time: 7min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = {}\n",
    "\n",
    "pybrain_classification(X_deleted, y_deleted, results, 'deleted')\n",
    "pybrain_classification(X_random, Y, results, 'random')\n",
    "pybrain_classification(X_mean, Y, results, 'mean')\n",
    "pybrain_classification(X_median, Y, results, 'median')\n",
    "pybrain_classification(X_mode, Y, results, 'mode')\n",
    "pybrain_classification(X_class_mode, Y, results, 'class_mode')\n",
    "pybrain_classification(X_class_mean, Y, results, 'class_mean')\n",
    "pybrain_classification(X_class_median, Y, results, 'class_median')\n",
    "pybrain_classification(X_knn, y_knn, results, 'knn_for_miss_val')\n",
    "pybrain_classification(X_closest_fit, y_closest_fit, results, 'closest_fit')\n",
    "pybrain_classification(X_pybrain, y_pybrain, results, 'pybrain')\n",
    "pybrain_classification(X_svm, y_svm, results, 'svm')\n",
    "pybrain_classification(X_lr, y_lr, results, 'lr')\n",
    "pybrain_classification(X_nb, y_nb, results, 'nb')\n",
    "\n",
    "import operator\n",
    "results_sorted_by_maxAcc = sorted(results.iteritems(), key=operator.itemgetter(1), reverse=True)\n",
    "for item in results_sorted_by_maxAcc:\n",
    "    print item[1], item[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.820502247979\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "pybrain_classification(X_lr, y_lr, results, 'lr')\n",
    "print results['lr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.81788104490500868, 53) class_mean\n",
      "(0.81687715889464596, 53) class_median\n",
      "(0.81167422279792745, 50) class_mode\n",
      "(0.80554218313685344, 50) closest_fit\n",
      "(0.80541342832469776, 56) median\n",
      "(0.8023281275665568, 56) knn_for_miss_val\n",
      "(0.8023281275665568, 50) nb\n",
      "(0.80126442010032473, 77) lr\n",
      "(0.80125755613126093, 50) mean\n",
      "(0.80023747841105364, 53) mode\n",
      "(0.8001775267553668, 50) svm\n",
      "(0.79919041450777206, 50) random\n",
      "(0.79694977364806585, 53) pybrain\n",
      "(0.78421500919300491, 56) deleted\n",
      "CPU times: user 2min 20s, sys: 276 ms, total: 2min 20s\n",
      "Wall time: 2min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = {}\n",
    "\n",
    "random_forest_classification(X_deleted, y_deleted, results, 'deleted', 50, 80, 3)\n",
    "random_forest_classification(X_random, Y, results, 'random', 50, 80, 3)\n",
    "random_forest_classification(X_mean, Y, results, 'mean', 50, 80, 3)\n",
    "random_forest_classification(X_median, Y, results, 'median', 50, 80, 3)\n",
    "random_forest_classification(X_mode, Y, results, 'mode', 50, 80, 3)\n",
    "random_forest_classification(X_class_mode, Y, results, 'class_mode', 50, 80, 3)\n",
    "random_forest_classification(X_class_mean, Y, results, 'class_mean', 50, 80, 3)\n",
    "random_forest_classification(X_class_median, Y, results, 'class_median', 50, 80, 3)\n",
    "random_forest_classification(X_knn, y_knn, results, 'knn_for_miss_val', 50, 80, 3)\n",
    "random_forest_classification(X_closest_fit, y_closest_fit, results, 'closest_fit', 50, 80, 3)\n",
    "random_forest_classification(X_svm, y_svm, results, 'svm', 50, 80, 3)\n",
    "random_forest_classification(X_lr, y_lr, results, 'lr', 50, 80, 3)\n",
    "random_forest_classification(X_nb, y_nb, results, 'nb', 50, 80, 3)\n",
    "random_forest_classification(X_pybrain, y_pybrain, results, 'pybrain', 50, 80, 3)\n",
    "    \n",
    "sort_and_print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.80016995432555205, 77)\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "random_forest_classification(X_lr, y_lr, results, 'lr', 50, 80, 3)\n",
    "print results['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 BI-RADS 0.69723965102\n",
      "2 Age 0.183219378639\n",
      "3 Margin 0.0444547075758\n",
      "4 Shape 0.0550552004878\n",
      "5 Density 0.0200310622776\n"
     ]
    }
   ],
   "source": [
    "from numpy import argsort\n",
    "\n",
    "most_important_features = argsort(rf.feature_importances_)[::-1]\n",
    "\n",
    "index = 0\n",
    "while index < len(list(X_deleted.columns)) and clf.feature_importances_[most_important_features[index]] > 0.01:\n",
    "    print index + 1, X_deleted.columns.values[most_important_features[index]], clf.feature_importances_[most_important_features[index]]\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.83871437823834183, 'LinearSVC') class_mode\n",
      "(0.83767810880829019, 'LinearSVC') class_median\n",
      "(0.83455310880829026, 'SVC') class_mean\n",
      "(0.83358060725522143, 'SVC') knn_for_miss_val\n",
      "(0.83034905171651319, 'SVC') nb\n",
      "(0.83034317627585508, 'SVC') closest_fit\n",
      "(0.83020272989912469, 'SVC') svm\n",
      "(0.83001370752470949, 'SVC') deleted\n",
      "(0.82936096718480135, 'SVC') median\n",
      "(0.82936096718480135, 'SVC') mode\n",
      "(0.8293555699481866, 'SVC') mean\n",
      "(0.8282043263459814, 'SVC') lr\n",
      "(0.82804644216408929, 'SVC') pybrain\n",
      "(0.82623596718480141, 'LinearSVC') random\n",
      "CPU times: user 8.94 s, sys: 12 ms, total: 8.95 s\n",
      "Wall time: 8.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = {}\n",
    "\n",
    "SVMClassification(X_deleted, y_deleted, results, 'deleted')\n",
    "SVMClassification(X_random, Y, results, 'random')\n",
    "SVMClassification(X_mean, Y, results, 'mean')\n",
    "SVMClassification(X_median, Y, results, 'median')\n",
    "SVMClassification(X_mode, Y, results, 'mode')\n",
    "SVMClassification(X_class_mode, Y, results, 'class_mode')\n",
    "SVMClassification(X_class_mean, Y, results, 'class_mean')\n",
    "SVMClassification(X_class_median, Y, results, 'class_median')\n",
    "SVMClassification(X_knn, y_knn, results, 'knn_for_miss_val')\n",
    "SVMClassification(X_closest_fit, y_closest_fit, results, 'closest_fit')\n",
    "SVMClassification(X_pybrain, y_pybrain, results, 'pybrain')\n",
    "SVMClassification(X_svm, y_svm, results, 'svm')\n",
    "SVMClassification(X_lr, y_lr, results, 'lr')\n",
    "SVMClassification(X_nb, y_nb, results, 'nb')\n",
    "    \n",
    "sort_and_print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.82805219226471605, 'SVC')\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "SVMClassification(X_lr, y_lr, results, 'lr')\n",
    "print results['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.83766731433506048, 'sag') class_mode\n",
      "(0.83766731433506048, 'sag') class_median\n",
      "(0.83246977547495682, 'sag') class_mean\n",
      "(0.82726144214162356, 'sag') mean\n",
      "(0.82606566594645137, 'sag') knn_for_miss_val\n",
      "(0.82518890328151995, 'sag') median\n",
      "(0.8249845848653703, 'sag') closest_fit\n",
      "(0.82414723661485323, 'sag') random\n",
      "(0.8228282349670849, 'liblinear') lr\n",
      "(0.82282242270320816, 'sag') nb\n",
      "(0.82163532861825084, 'sag') pybrain\n",
      "(0.82057156000230003, 'sag') svm\n",
      "(0.81999136442141629, 'sag') mode\n",
      "(0.81681128433166528, 'sag') deleted\n",
      "CPU times: user 2.31 s, sys: 5 µs, total: 2.31 s\n",
      "Wall time: 2.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = {}\n",
    "\n",
    "logisticRegClassification(X_deleted, y_deleted, results, 'deleted')\n",
    "logisticRegClassification(X_random, Y, results, 'random')\n",
    "logisticRegClassification(X_mean, Y, results, 'mean')\n",
    "logisticRegClassification(X_median, Y, results, 'median')\n",
    "logisticRegClassification(X_mode, Y, results, 'mode')\n",
    "logisticRegClassification(X_class_mode, Y, results, 'class_mode')\n",
    "logisticRegClassification(X_class_mean, Y, results, 'class_mean')\n",
    "logisticRegClassification(X_class_median, Y, results, 'class_median')\n",
    "logisticRegClassification(X_knn, y_knn, results, 'knn_for_miss_val')\n",
    "logisticRegClassification(X_closest_fit, y_closest_fit, results, 'closest_fit')\n",
    "logisticRegClassification(X_pybrain, y_pybrain, results, 'pybrain')\n",
    "logisticRegClassification(X_lr, y_lr, results, 'lr')\n",
    "logisticRegClassification(X_nb, y_nb, results, 'nb')\n",
    "logisticRegClassification(X_svm, y_svm, results, 'svm')\n",
    "    \n",
    "sort_and_print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.82056005980104652, 'sag')\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "logisticRegClassification(X_lr, y_lr, results, 'lr')\n",
    "print results['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.832464378238 class_mode\n",
      "0.831422711572 class_median\n",
      "0.826225172712 class_mean\n",
      "0.816866364421 mean\n",
      "0.815819300518 random\n",
      "0.814783031088 median\n",
      "0.814214396725 knn_for_miss_val\n",
      "0.814148697602 svm\n",
      "0.812715889465 mode\n",
      "0.812058046827 closest_fit\n",
      "0.81091714105 pybrain\n",
      "0.810823347828 deleted\n",
      "0.809895884664 lr\n",
      "0.809895884664 nb\n",
      "CPU times: user 241 ms, sys: 4 ms, total: 245 ms\n",
      "Wall time: 245 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = {}\n",
    "\n",
    "NBClassification(X_deleted, y_deleted, results, 'deleted')\n",
    "NBClassification(X_random, Y, results, 'random')\n",
    "NBClassification(X_mean, Y, results, 'mean')\n",
    "NBClassification(X_median, Y, results, 'median')\n",
    "NBClassification(X_mode, Y, results, 'mode')\n",
    "NBClassification(X_class_mode, Y, results, 'class_mode')\n",
    "NBClassification(X_class_mean, Y, results, 'class_mean')\n",
    "NBClassification(X_class_median, Y, results, 'class_median')\n",
    "NBClassification(X_knn, y_knn, results, 'knn_for_miss_val')\n",
    "NBClassification(X_closest_fit, y_closest_fit, results, 'closest_fit')\n",
    "NBClassification(X_pybrain, y_pybrain, results, 'pybrain')\n",
    "NBClassification(X_svm, y_svm, results, 'svm')\n",
    "NBClassification(X_nb, y_nb, results, 'nb')\n",
    "NBClassification(X_lr, y_lr, results, 'lr')\n",
    "    \n",
    "sort_and_print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.811992409867\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "NBClassification(X_lr, y_lr, results, 'lr')\n",
    "print results['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###Датасет маркетинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>YearsInSf</th>\n",
       "      <th>DualIncome</th>\n",
       "      <th>HouseholdMembers</th>\n",
       "      <th>Under18</th>\n",
       "      <th>HouseholdStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex  MaritalStatus  Age  Education  Occupation  YearsInSf  DualIncome  \\\n",
       "0    2              1    5          4           5          5           3   \n",
       "1    1              1    5          5           5          5           3   \n",
       "2    2              1    3          5           1          5           2   \n",
       "3    2              5    1          2           6          5           1   \n",
       "4    2              5    1          2           6          3           1   \n",
       "5    1              1    6          4           8          5           3   \n",
       "6    1              5    2          3           9          4           1   \n",
       "7    1              3    3          4           3          5           1   \n",
       "8    1              1    6          3           8          5           3   \n",
       "9    1              1    7          4           8          4           3   \n",
       "\n",
       "   HouseholdMembers  Under18  HouseholdStatus  \n",
       "0                 3        0                1  \n",
       "1                 5        2                1  \n",
       "2                 3        1                2  \n",
       "3                 4        2                3  \n",
       "4                 4        2                3  \n",
       "5                 2        0                1  \n",
       "6                 3        1                2  \n",
       "7                 1        0                2  \n",
       "8                 3        0                2  \n",
       "9                 2        0                2  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_data('marketing.dat')\n",
    "data[data.columns[:10]][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#выделям из данных Х и Y\n",
    "columns = list(data.columns.values)\n",
    "X_columns = columns[:-1]\n",
    "y_column = columns[-1]\n",
    "X = data[X_columns]\n",
    "Y = data[y_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8993, 14)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>YearsInSf</th>\n",
       "      <th>DualIncome</th>\n",
       "      <th>HouseholdMembers</th>\n",
       "      <th>Under18</th>\n",
       "      <th>HouseholdStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex  MaritalStatus  Age  Education  Occupation  YearsInSf  DualIncome  \\\n",
       "1    1              1    5          5           5          5           3   \n",
       "2    2              1    3          5           1          5           2   \n",
       "3    2              5    1          2           6          5           1   \n",
       "4    2              5    1          2           6          3           1   \n",
       "5    1              1    6          4           8          5           3   \n",
       "\n",
       "   HouseholdMembers  Under18  HouseholdStatus  \n",
       "1                 5        2                1  \n",
       "2                 3        1                2  \n",
       "3                 4        2                3  \n",
       "4                 4        2                3  \n",
       "5                 2        0                1  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#удалим объекты с пропущенными значениями\n",
    "\n",
    "data_deleted = data.dropna()\n",
    "X_deleted = data_deleted[columns[:-1]]\n",
    "y_deleted = data_deleted[columns[-1]]\n",
    "X_deleted[X_deleted.columns[:10]][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_random, X_mean, X_median, X_mode, X_class_mean, X_class_median, X_class_mode = imputMissingValues(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class': ['Sex',\n",
       "  'MaritalStatus',\n",
       "  'Age',\n",
       "  'Education',\n",
       "  'Occupation',\n",
       "  'YearsInSf',\n",
       "  'DualIncome',\n",
       "  'HouseholdMembers',\n",
       "  'HouseholdStatus',\n",
       "  'TypeOfHome',\n",
       "  'EthnicClass',\n",
       "  'Language'],\n",
       " 'regr': ['Under18']}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devided_features = devide_features_to_classifiable_and_regressiable(X, 10)\n",
    "devided_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.593368092266 7\n",
      "0.812099277237 12\n",
      "0.520349121969 18\n",
      "0.416078074667 17\n",
      "0.524451596758 19\n",
      "0.640485031123 17\n",
      "0.868236122523 18\n",
      "0.574761565253 9\n",
      "0.80540714677 8\n",
      "0.736900200179 19\n",
      "0.709714643812 18\n",
      "0.914922003089 8\n",
      "CPU times: user 10min 58s, sys: 236 ms, total: 10min 58s\n",
      "Wall time: 10min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#метод ближайших соседей\n",
    "#для начала пойдем самым простым путем - для обучения воспользуемся только полностью заполненными объектами\n",
    "\n",
    "X_knn = X.copy()\n",
    "\n",
    "for column_name in devided_featres['class']:\n",
    "    current_X_columns = copy(X_columns)\n",
    "    current_X_columns.remove(column_name)\n",
    "    \n",
    "    #обучение\n",
    "    current_y = X_deleted[column_name]\n",
    "    current_X = X_deleted[current_X_columns]\n",
    "    \n",
    "    max_acc = 0\n",
    "    best_neigh_num = 0\n",
    "    epsilon = 0.005\n",
    "\n",
    "    for neighbors_num in xrange(3, 20):\n",
    "        knn = KNeighborsClassifier(metric = 'manhattan', n_neighbors = neighbors_num)\n",
    "        #knn = KNeighborsClassifier(n_neighbors=neighbors_num)\n",
    "        X_scaled = StandardScaler().fit_transform(current_X)\n",
    "        mean_acc_score = cross_val_score(knn, X_scaled, current_y, cv=5).mean()\n",
    "\n",
    "        if mean_acc_score > max_acc + epsilon:\n",
    "            max_acc = mean_acc_score\n",
    "            best_neigh_num = neighbors_num\n",
    "\n",
    "    print max_acc, best_neigh_num\n",
    "    \n",
    "    current_X, X_train, y_train, X_test = get_X_and_y_by_column_name(X, current_X_columns, column_name)\n",
    "            \n",
    "    #применение knn\n",
    "    if len(X_test.index) > 0:\n",
    "        knn_for_missing_values = KNeighborsClassifier(metric = 'manhattan', n_neighbors=best_neigh_num)\n",
    "        #knn_for_missing_values = KNeighborsClassifier(n_neighbors=best_neigh_num)\n",
    "        scaler = StandardScaler().fit(current_X)\n",
    "        knn_for_missing_values.fit(scaler.transform(X_train), y_train)\n",
    "        y_test = knn_for_missing_values.predict(scaler.transform(X_test))\n",
    "        X_test_indices = list(X_test.index.values)\n",
    "        counter = 0\n",
    "        for index in X_test_indices:\n",
    "            X_knn.set_value(index, column_name, y_test[counter])\n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#для X_knn соберем y_knn\n",
    "X_knn = X_knn.dropna()\n",
    "y_knn = pd.Series()\n",
    "for index in list(X_knn.index.values):\n",
    "    y_knn.set_value(index, Y.loc[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 856 µs, sys: 0 ns, total: 856 µs\n",
      "Wall time: 818 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#svm\n",
    "\n",
    "X_svm = X.copy()\n",
    "\n",
    "for column_name in devided_features['class']:\n",
    "    print column_name\n",
    "    current_X_columns = list(X_svm.columns)\n",
    "    current_X_columns.remove(column_name)\n",
    "    \n",
    "    current_X, X_train, y_train, X_test = get_X_and_y_by_column_name(X_svm, current_X_columns, column_name)\n",
    "    \n",
    "    clf = svm.SVC()\n",
    "    \n",
    "    print X_test[:10]\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    clf.fit(scaler.transform(X_train), y_train)\n",
    "    y_test = clf.predict(scaler.transform(X_test))\n",
    "    \n",
    "    addImputedValuesToDF(X_svm, y_test, list(X_test.index.values), column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#svm\n",
    "for column_name in devided_features['regr']:\n",
    "    current_X_columns = list(X_svm.columns)\n",
    "    current_X_columns.remove(column_name)\n",
    "    \n",
    "    current_X, X_train, y_train, X_test = get_X_and_y_by_column_name(X_svm, current_X_columns, column_name)\n",
    "    \n",
    "    clf = svm.SVR()\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    clf.fit(scaler.transform(X_train), y_train)\n",
    "    y_test = clf.predict(scaler.transform(X_test))\n",
    "    \n",
    "    addImputedValuesToDF(X_svm, y_test, list(X_test.index.values), column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.583624858825 9\n",
      "0.803221980195 9\n",
      "0.478034272526 9\n",
      "0.389611846279 9\n",
      "0.508308306696 9\n",
      "0.616198852899 9\n",
      "0.86081920705 9\n",
      "0.438622308272 9\n",
      "0.788100379288 9\n",
      "0.697196662332 9\n",
      "0.704047196427 9\n",
      "0.91215540397 9\n",
      "CPU times: user 1h 46min 37s, sys: 2.59 s, total: 1h 46min 40s\n",
      "Wall time: 1h 46min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#closest_fit\n",
    "X_closest_fit = X.copy()\n",
    "\n",
    "max_min_differences = get_max_min_differences_array_from_data(X_deleted)\n",
    "\n",
    "for column_name in devided_featres['class']:\n",
    "    current_X_columns = copy(devided_featres['class'])\n",
    "    current_X_columns.remove(column_name)\n",
    "    \n",
    "    #обучение\n",
    "    current_y = X_deleted[column_name]\n",
    "    current_X = X_deleted[current_X_columns]\n",
    "    \n",
    "    max_acc = 0\n",
    "    best_neigh_num = 0\n",
    "    epsilon = 0.005\n",
    "    max_min_differences = get_max_min_differences_array_from_data(X_deleted)\n",
    "\n",
    "    for neighbors_num in xrange(9, 10):\n",
    "        knn = KNeighborsClassifier(n_neighbors=neighbors_num,\n",
    "                                   metric=closest_fit_metric,\n",
    "                                   metric_params={'max_min_differences':max_min_differences})\n",
    "        X_scaled = StandardScaler().fit_transform(current_X)\n",
    "        mean_acc_score = cross_val_score(knn, X_scaled, current_y, cv=5).mean()\n",
    "\n",
    "        if mean_acc_score > max_acc + epsilon:\n",
    "            max_acc = mean_acc_score\n",
    "            best_neigh_num = neighbors_num\n",
    "\n",
    "    print max_acc, best_neigh_num\n",
    "    \n",
    "    current_X, X_train, y_train, X_test = get_X_and_y_by_column_name(X, current_X_columns, column_name)\n",
    "            \n",
    "    max_min_differences = get_max_min_differences_array_from_data(current_X)\n",
    "            \n",
    "    #применение knn\n",
    "    if len(X_test.index) > 0:\n",
    "        knn_for_missing_values = KNeighborsClassifier(n_neighbors=best_neigh_num,\n",
    "                                                      metric=closest_fit_metric,\n",
    "                                                      metric_params={'max_min_differences':max_min_differences})\n",
    "        scaler = StandardScaler().fit(current_X)\n",
    "        knn_for_missing_values.fit(scaler.transform(X_train), y_train)\n",
    "        y_test = knn_for_missing_values.predict(scaler.transform(X_test))\n",
    "        X_test_indices = list(X_test.index.values)\n",
    "        counter = 0\n",
    "        for index in X_test_indices:\n",
    "            X_closest_fit.set_value(index, column_name, y_test[counter])\n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#для X_closest_fit соберем y_closest_fit\n",
    "X_closest_fit = X_closest_fit.dropna()\n",
    "y_closest_fit = pd.Series()\n",
    "for index in list(X_closest_fit.index.values):\n",
    "    y_closest_fit.set_value(index, Y.loc[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15 µs, sys: 0 ns, total: 15 µs\n",
      "Wall time: 21 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from rep.estimators.pybrain import PyBrainClassifier\n",
    "\n",
    "X_pybrain = X.copy()\n",
    "\n",
    "for column_name in devided_featres['class']:\n",
    "    current_X_columns = copy(X_columns)\n",
    "    current_X_columns.remove(column_name)\n",
    "    \n",
    "    current_X, X_train, y_train, X_test = get_X_and_y_by_column_name(X, current_X_columns, column_name)\n",
    "    fitted_y, values_map = fit_y(y_train)\n",
    "    \n",
    "    print 'i'\n",
    "    \n",
    "    pb_for_missing_values = PyBrainClassifier(layers=[10],\n",
    "                                              epochs=10,\n",
    "                                              verbose=False)\n",
    "    pb_for_missing_values.fit(X_train, fitted_y)\n",
    "    y_test_fitted = pb_for_missing_values.predict(X_test)\n",
    "    \n",
    "    y_test = decrypt_y(pd.Series(y_test_fitted), values_map)\n",
    "    X_test_indices = list(X_test.index.values)\n",
    "    counter = 0\n",
    "    for index in X_test_indices:\n",
    "        X_pybrain.set_value(index, column_name, y_test[counter])\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.32315386165730742, 19) random\n",
      "(0.32292632192448278, 17) class_mean\n",
      "(0.32081489463761903, 15) class_median\n",
      "(0.32011299048393993, 15) deleted\n",
      "(0.31992538929589659, 14) class_mode\n",
      "(0.31970168194882664, 15) mean\n",
      "(0.31958976392611133, 16) mode\n",
      "(0.318037265780517, 15) knn_for_miss_val\n",
      "(0.31702672634669782, 16) median\n",
      "CPU times: user 3min 44s, sys: 52.1 ms, total: 3min 44s\n",
      "Wall time: 3min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = {}\n",
    "\n",
    "neighbors(X_deleted, y_deleted, results, 'deleted', 10, 20)\n",
    "neighbors(X_random, Y, results, 'random', 10, 20)\n",
    "neighbors(X_mean, Y, results, 'mean', 10, 20)\n",
    "neighbors(X_median, Y, results, 'median', 10, 20)\n",
    "neighbors(X_mode, Y, results, 'mode', 10, 20)\n",
    "neighbors(X_class_mode, Y, results, 'class_mode', 10, 20)\n",
    "neighbors(X_class_mean, Y, results, 'class_mean', 10, 20)\n",
    "neighbors(X_class_median, Y, results, 'class_median', 10, 20)\n",
    "neighbors(X_knn, y_knn, results, 'knn_for_miss_val', 10, 20)\n",
    "#neighbors(X_closest_fit, y_closest_fit, results, 'closest_fit')\n",
    "#neighbors(X_pybrain, y_pybrain, results, 'pybrain')\n",
    "\n",
    "sort_and_print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.335051473322 class_mode\n",
      "0.332712386697 median\n",
      "0.329375213613 class_median\n",
      "0.328568720585 knn_for_miss_val\n",
      "0.327817017688 deleted\n",
      "0.32759595382 mode\n",
      "0.32737051779 random\n",
      "0.32292669009 mean\n",
      "0.320923468048 class_mean\n",
      "CPU times: user 1h 3min 44s, sys: 22 s, total: 1h 4min 6s\n",
      "Wall time: 1h 4min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = {}\n",
    "\n",
    "pybrain_classification(X_deleted, y_deleted, results, 'deleted')\n",
    "pybrain_classification(X_random, Y, results, 'random')\n",
    "pybrain_classification(X_mean, Y, results, 'mean')\n",
    "pybrain_classification(X_median, Y, results, 'median')\n",
    "pybrain_classification(X_mode, Y, results, 'mode')\n",
    "pybrain_classification(X_class_mode, Y, results, 'class_mode')\n",
    "pybrain_classification(X_class_mean, Y, results, 'class_mean')\n",
    "pybrain_classification(X_class_median, Y, results, 'class_median')\n",
    "pybrain_classification(X_knn, y_knn, results, 'knn_for_miss_val')\n",
    "#pybrain_classification(X_closest_fit, y_closest_fit, results, 'closest_fit')\n",
    "#pybrain_classification(X_pybrain, y_pybrain, results, 'pybrain')\n",
    "\n",
    "sort_and_print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.35393988659190201, 50) class_mean\n",
      "(0.3161483502650132, 50) class_median\n",
      "(0.31458475137807412, 71) mean\n",
      "(0.31291839587113202, 50) class_mode\n",
      "(0.31247431367499329, 53) median\n",
      "(0.30979500828563067, 56) deleted\n",
      "(0.30892161497327969, 50) random\n",
      "(0.30769412481966396, 50) mode\n",
      "(0.30367541867115727, 50) knn_for_miss_val\n",
      "CPU times: user 6min 25s, sys: 2.68 s, total: 6min 28s\n",
      "Wall time: 6min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = {}\n",
    "\n",
    "random_forest_classification(X_deleted, y_deleted, results, 'deleted', 50, 80, 3)\n",
    "random_forest_classification(X_random, Y, results, 'random', 50, 80, 3)\n",
    "random_forest_classification(X_mean, Y, results, 'mean', 50, 80, 3)\n",
    "random_forest_classification(X_median, Y, results, 'median', 50, 80, 3)\n",
    "random_forest_classification(X_mode, Y, results, 'mode', 50, 80, 3)\n",
    "random_forest_classification(X_class_mode, Y, results, 'class_mode', 50, 80, 3)\n",
    "random_forest_classification(X_class_mean, Y, results, 'class_mean', 50, 80, 3)\n",
    "random_forest_classification(X_class_median, Y, results, 'class_median', 50, 80, 3)\n",
    "random_forest_classification(X_knn, y_knn, results, 'knn_for_miss_val', 50, 80, 3)\n",
    "#random_forest_classification(X_closest_fit, y_closest_fit, results, 'closest_fit')\n",
    "#random_forest_classification(X_pybrain, y_pybrain, results, 'pybrain')\n",
    "\n",
    "sort_and_print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 28s, sys: 76 ms, total: 1min 28s\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = {}\n",
    "\n",
    "SVMMultiClassification(X_deleted, y_deleted, results, 'deleted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.3487205631652518, 'SVC') class_median\n",
      "(0.34683297219219511, 'SVC') class_mode\n",
      "(0.34282777008849835, 'SVC') median\n",
      "(0.34082727537185054, 'SVC') mode\n",
      "(0.33982572745227702, 'SVC') class_mean\n",
      "(0.33974233309434421, 'SVC') deleted\n",
      "(0.33965133151464255, 'SVC') knn_for_miss_val\n",
      "(0.33926763811037264, 'SVC') mean\n",
      "(0.33571158130496731, 'SVC') random\n",
      "CPU times: user 19min 29s, sys: 100 ms, total: 19min 29s\n",
      "Wall time: 19min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = {}\n",
    "\n",
    "SVMMultiClassification(X_deleted, y_deleted, results, 'deleted')\n",
    "SVMMultiClassification(X_random, Y, results, 'random')\n",
    "SVMMultiClassification(X_mean, Y, results, 'mean')\n",
    "SVMMultiClassification(X_median, Y, results, 'median')\n",
    "SVMMultiClassification(X_mode, Y, results, 'mode')\n",
    "SVMMultiClassification(X_class_mode, Y, results, 'class_mode')\n",
    "SVMMultiClassification(X_class_mean, Y, results, 'class_mean')\n",
    "SVMMultiClassification(X_class_median, Y, results, 'class_median')\n",
    "SVMMultiClassification(X_knn, y_knn, results, 'knn_for_miss_val')\n",
    "#SVMMultiClassification(X_closest_fit, y_closest_fit, results, 'closest_fit')\n",
    "#SVMMultiClassification(X_pybrain, y_pybrain, results, 'pybrain')\n",
    "\n",
    "sort_and_print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.32325748303574403, 'sag') class_median\n",
      "(0.32225853183349817, 'lbfgs') class_mode\n",
      "(0.32114408181917264, 'lbfgs') class_mean\n",
      "(0.31951772327233285, 'liblinear') deleted\n",
      "(0.31780913866913701, 'liblinear') mean\n",
      "(0.31769511913595094, 'newton-cg') median\n",
      "(0.31733584325690184, 'lbfgs') knn_for_miss_val\n",
      "(0.31691950546357772, 'sag') mode\n",
      "(0.31547833657800639, 'sag') random\n",
      "CPU times: user 1min 12s, sys: 7.98 ms, total: 1min 12s\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = {}\n",
    "\n",
    "logisticRegClassification(X_deleted, y_deleted, results, 'deleted')\n",
    "logisticRegClassification(X_random, Y, results, 'random')\n",
    "logisticRegClassification(X_mean, Y, results, 'mean')\n",
    "logisticRegClassification(X_median, Y, results, 'median')\n",
    "logisticRegClassification(X_mode, Y, results, 'mode')\n",
    "logisticRegClassification(X_class_mode, Y, results, 'class_mode')\n",
    "logisticRegClassification(X_class_mean, Y, results, 'class_mean')\n",
    "logisticRegClassification(X_class_median, Y, results, 'class_median')\n",
    "logisticRegClassification(X_knn, y_knn, results, 'knn_for_miss_val')\n",
    "#logisticRegClassification(X_closest_fit, y_closest_fit, results, 'closest_fit')\n",
    "#logisticRegClassification(X_pybrain, y_pybrain, results, 'pybrain')\n",
    "    \n",
    "sort_and_print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.308809936995 class_mode\n",
      "0.308254073728 class_median\n",
      "0.307753440903 deleted\n",
      "0.307030302967 class_mean\n",
      "0.305027827711 median\n",
      "0.304805357132 random\n",
      "0.304360045601 mean\n",
      "0.304359302934 mode\n",
      "CPU times: user 694 ms, sys: 0 ns, total: 694 ms\n",
      "Wall time: 694 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = {}\n",
    "\n",
    "NBClassification(X_deleted, y_deleted, results, 'deleted')\n",
    "NBClassification(X_random, Y, results, 'random')\n",
    "NBClassification(X_mean, Y, results, 'mean')\n",
    "NBClassification(X_median, Y, results, 'median')\n",
    "NBClassification(X_mode, Y, results, 'mode')\n",
    "NBClassification(X_class_mode, Y, results, 'class_mode')\n",
    "NBClassification(X_class_mean, Y, results, 'class_mean')\n",
    "NBClassification(X_class_median, Y, results, 'class_median')\n",
    "#NBClassification(X_knn, y_knn, results, 'knn_for_miss_val')\n",
    "#NBClassification(X_closest_fit, y_closest_fit, results, 'closest_fit')\n",
    "#NBClassification(X_pybrain, y_pybrain, results, 'pybrain')\n",
    "    \n",
    "sort_and_print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNumAndCatFeatures(X):\n",
    "    num_columns = []\n",
    "    cat_columns = []\n",
    "    \n",
    "    for column in X.columns:\n",
    "        if type(X[column].dropna().iloc[0]) == str:\n",
    "            cat_columns.append(column)\n",
    "        else:\n",
    "            num_columns.append(column)\n",
    "            \n",
    "    return (num_columns, cat_columns)\n",
    "\n",
    "def getMissingDataRate(df):\n",
    "    \n",
    "    N = df.shape[0] * df.shape[1]\n",
    "    naValues = 0\n",
    "    \n",
    "    for label in df.columns:\n",
    "        nanValInCol = df[label].isnull()\n",
    "        if True in nanValInCol.value_counts().index:\n",
    "            naValues += nanValInCol.value_counts()[True]\n",
    "        \n",
    "    return  float(naValues) / N\n",
    "\n",
    "def setNanValuesToDataframe(df):\n",
    "    df_copy = df.copy()\n",
    "    rand_indices = random.sample(range(df_copy.shape[0]), df_copy.shape[0] / 2)\n",
    "    for i in rand_indices:\n",
    "        rand_cols = random.sample(df_copy.columns.values, max(1, df_copy.shape[1] / 3))\n",
    "        for col in rand_cols:\n",
    "            df_copy.set_value(i,\n",
    "                              col,\n",
    "                              None)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###обработка датасета с кэгла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_from_kaggle/kobe/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data.drop(['shot_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getMissingDataRate(data.drop('shot_made_flag', 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###то же для титаника"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_from_kaggle/titanic/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03310886644219978"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to use\n",
    "data = pd.read_csv('/home/tyamana/data_from_kaggle/titanic/train.csv')\n",
    "data = data.drop('PassengerId', 1)\n",
    "print(data.shape)\n",
    "X = data[data.columns.values[1:]]\n",
    "num_columns, _ = getNumAndCatfeatures(X)\n",
    "X = data[num_columns]\n",
    "Y = data[data.columns.values[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###приют для животных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_from_kaggle/animal_shelters/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AnimalID</th>\n",
       "      <th>Name</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>OutcomeType</th>\n",
       "      <th>OutcomeSubtype</th>\n",
       "      <th>AnimalType</th>\n",
       "      <th>SexuponOutcome</th>\n",
       "      <th>AgeuponOutcome</th>\n",
       "      <th>Breed</th>\n",
       "      <th>Color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A671945</td>\n",
       "      <td>Hambone</td>\n",
       "      <td>2014-02-12 18:22:00</td>\n",
       "      <td>Return_to_owner</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>1 year</td>\n",
       "      <td>Shetland Sheepdog Mix</td>\n",
       "      <td>Brown/White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  AnimalID     Name             DateTime      OutcomeType OutcomeSubtype  \\\n",
       "0  A671945  Hambone  2014-02-12 18:22:00  Return_to_owner            NaN   \n",
       "\n",
       "  AnimalType SexuponOutcome AgeuponOutcome                  Breed        Color  \n",
       "0        Dog  Neutered Male         1 year  Shetland Sheepdog Mix  Brown/White  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:1] #пока не наш вариант"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Don't get kicked! set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_from_kaggle/dont_get_kicked/training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10723240115718419"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#touse\n",
    "data = pd.read_csv('/home/tyamana/data_from_kaggle/dont_get_kicked/training.csv')\n",
    "data = data.drop('RefId', axis=1)\n",
    "data = data.sample(frac=0.09, random_state=410)\n",
    "print(data.shape)\n",
    "X = data[data.columns.values[1:]]\n",
    "num_columns, _ = getNumAndCatfeatures(X)\n",
    "X = data[num_columns]\n",
    "Y = data[data.columns.values[0]]\n",
    "setNanValuesToDataframe(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###CASP(REGRESSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_from_kaggle/chess/primary_training_part1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(624148, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getMissingDataRate(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data.drop('PTID', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###bikesharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1089, 11)\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/home/tyamana/data_from_kaggle/bikesharing/train.csv')\n",
    "num_columns, _ = getNumAndCatFeatures(data)\n",
    "data = data[num_columns]\n",
    "data = data.sample(frac=0.1, random_state=510)\n",
    "print(data.shape)\n",
    "X = data[data.columns.values[:-1]]\n",
    "Y = data[data.columns.values[-1]]\n",
    "#X = setNanValuesToDataframe(X)\n",
    "\n",
    "print(getMissingDataRate(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###scillcraft "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('missing_values/datasets/scillcraft/train.csv', na_values='?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GameID</th>\n",
       "      <th>LeagueIndex</th>\n",
       "      <th>Age</th>\n",
       "      <th>HoursPerWeek</th>\n",
       "      <th>TotalHours</th>\n",
       "      <th>APM</th>\n",
       "      <th>SelectByHotkeys</th>\n",
       "      <th>AssignToHotkeys</th>\n",
       "      <th>UniqueHotkeys</th>\n",
       "      <th>MinimapAttacks</th>\n",
       "      <th>MinimapRightClicks</th>\n",
       "      <th>NumberOfPACs</th>\n",
       "      <th>GapBetweenPACs</th>\n",
       "      <th>ActionLatency</th>\n",
       "      <th>ActionsInPAC</th>\n",
       "      <th>TotalMapExplored</th>\n",
       "      <th>WorkersMade</th>\n",
       "      <th>UniqueUnitsMade</th>\n",
       "      <th>ComplexUnitsMade</th>\n",
       "      <th>ComplexAbilitiesUsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>3000</td>\n",
       "      <td>143.7180</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.004849</td>\n",
       "      <td>32.6677</td>\n",
       "      <td>40.8673</td>\n",
       "      <td>4.7508</td>\n",
       "      <td>28</td>\n",
       "      <td>0.001397</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>5000</td>\n",
       "      <td>129.2322</td>\n",
       "      <td>0.003304</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.004307</td>\n",
       "      <td>32.9194</td>\n",
       "      <td>42.3454</td>\n",
       "      <td>4.8434</td>\n",
       "      <td>22</td>\n",
       "      <td>0.001194</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GameID  LeagueIndex  Age  HoursPerWeek  TotalHours       APM  \\\n",
       "0      52            5   27            10        3000  143.7180   \n",
       "1      55            5   23            10        5000  129.2322   \n",
       "\n",
       "   SelectByHotkeys  AssignToHotkeys  UniqueHotkeys  MinimapAttacks  \\\n",
       "0         0.003515         0.000220              7        0.000110   \n",
       "1         0.003304         0.000259              4        0.000294   \n",
       "\n",
       "   MinimapRightClicks  NumberOfPACs  GapBetweenPACs  ActionLatency  \\\n",
       "0            0.000392      0.004849         32.6677        40.8673   \n",
       "1            0.000432      0.004307         32.9194        42.3454   \n",
       "\n",
       "   ActionsInPAC  TotalMapExplored  WorkersMade  UniqueUnitsMade  \\\n",
       "0        4.7508                28     0.001397                6   \n",
       "1        4.8434                22     0.001194                5   \n",
       "\n",
       "   ComplexUnitsMade  ComplexAbilitiesUsed  \n",
       "0                 0              0.000000  \n",
       "1                 0              0.000208  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3395, 20)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002474226804123711"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getMissingDataRate(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###dowjones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('missing_values/datasets/dowjones/dow_jones_index.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num, _ = getNumAndCatFeatures(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data[num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750, 8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = data['percent_change_next_weeks_price']\n",
    "cols = list(data.columns.values)\n",
    "cols.remove('percent_change_next_weeks_price')\n",
    "X = data[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "X = Imputer().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.12809962174541764"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgr = KNeighborsRegressor(metric='manhattan', n_neighbors=10)\n",
    "\n",
    "r2 = cross_val_score(rgr, X, Y, cv=5, scoring='r2')\n",
    "r2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>previous_weeks_volume</th>\n",
       "      <th>next_weeks_open</th>\n",
       "      <th>next_weeks_close</th>\n",
       "      <th>percent_change_next_weeks_price</th>\n",
       "      <th>days_to_next_dividend</th>\n",
       "      <th>percent_return_next_dividend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>$16.71</td>\n",
       "      <td>$15.97</td>\n",
       "      <td>-4.428490</td>\n",
       "      <td>26</td>\n",
       "      <td>0.182704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>239655616</td>\n",
       "      <td>$16.19</td>\n",
       "      <td>$15.79</td>\n",
       "      <td>-2.470660</td>\n",
       "      <td>19</td>\n",
       "      <td>0.187852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>242963398</td>\n",
       "      <td>$15.87</td>\n",
       "      <td>$16.13</td>\n",
       "      <td>1.638310</td>\n",
       "      <td>12</td>\n",
       "      <td>0.189994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>138428495</td>\n",
       "      <td>$16.18</td>\n",
       "      <td>$17.14</td>\n",
       "      <td>5.933250</td>\n",
       "      <td>5</td>\n",
       "      <td>0.185989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151379173</td>\n",
       "      <td>$17.33</td>\n",
       "      <td>$17.37</td>\n",
       "      <td>0.230814</td>\n",
       "      <td>97</td>\n",
       "      <td>0.175029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>154387761</td>\n",
       "      <td>$17.39</td>\n",
       "      <td>$17.28</td>\n",
       "      <td>-0.632547</td>\n",
       "      <td>90</td>\n",
       "      <td>0.172712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>114691279</td>\n",
       "      <td>$16.98</td>\n",
       "      <td>$16.68</td>\n",
       "      <td>-1.766780</td>\n",
       "      <td>83</td>\n",
       "      <td>0.173611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80023895</td>\n",
       "      <td>$16.81</td>\n",
       "      <td>$16.58</td>\n",
       "      <td>-1.368230</td>\n",
       "      <td>76</td>\n",
       "      <td>0.179856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>132981863</td>\n",
       "      <td>$16.58</td>\n",
       "      <td>$16.03</td>\n",
       "      <td>-3.317250</td>\n",
       "      <td>69</td>\n",
       "      <td>0.180941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>109493077</td>\n",
       "      <td>$15.95</td>\n",
       "      <td>$16.11</td>\n",
       "      <td>1.003130</td>\n",
       "      <td>62</td>\n",
       "      <td>0.187149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   previous_weeks_volume next_weeks_open next_weeks_close  \\\n",
       "0                    NaN          $16.71           $15.97   \n",
       "1              239655616          $16.19           $15.79   \n",
       "2              242963398          $15.87           $16.13   \n",
       "3              138428495          $16.18           $17.14   \n",
       "4              151379173          $17.33           $17.37   \n",
       "5              154387761          $17.39           $17.28   \n",
       "6              114691279          $16.98           $16.68   \n",
       "7               80023895          $16.81           $16.58   \n",
       "8              132981863          $16.58           $16.03   \n",
       "9              109493077          $15.95           $16.11   \n",
       "\n",
       "   percent_change_next_weeks_price  days_to_next_dividend  \\\n",
       "0                        -4.428490                     26   \n",
       "1                        -2.470660                     19   \n",
       "2                         1.638310                     12   \n",
       "3                         5.933250                      5   \n",
       "4                         0.230814                     97   \n",
       "5                        -0.632547                     90   \n",
       "6                        -1.766780                     83   \n",
       "7                        -1.368230                     76   \n",
       "8                        -3.317250                     69   \n",
       "9                         1.003130                     62   \n",
       "\n",
       "   percent_return_next_dividend  \n",
       "0                      0.182704  \n",
       "1                      0.187852  \n",
       "2                      0.189994  \n",
       "3                      0.185989  \n",
       "4                      0.175029  \n",
       "5                      0.172712  \n",
       "6                      0.173611  \n",
       "7                      0.179856  \n",
       "8                      0.180941  \n",
       "9                      0.187149  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.columns.values[10:]][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getMissingDataRate(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###onlinenews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('missing_values/datasets/onlinenews/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_col, _ = getNumAndCatFeatures(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39644, 60)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[num_col].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data[num_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.sample(frac=0.1, random_state=282)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data[data.columns.values[:-1]]\n",
    "Y = data[data.columns.values[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_scaled = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.19714356, -0.14031447, -0.28846463, -0.24438042,  0.00309011])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor as KNR\n",
    "\n",
    "rgr = KNR(n_neighbors = 30, metric='manhattan')\n",
    "\n",
    "r2 = cross_val_score(rgr, X_scaled, Y, cv=5, scoring='r2')\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2832.3,  1496.1,  3252.8,  4344.4,  2059.3])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15427</th>\n",
       "      <td>434</td>\n",
       "      <td>14</td>\n",
       "      <td>559</td>\n",
       "      <td>0.522388</td>\n",
       "      <td>1</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.391771</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.377381</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.560606</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.068182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5442</th>\n",
       "      <td>632</td>\n",
       "      <td>10</td>\n",
       "      <td>311</td>\n",
       "      <td>0.537954</td>\n",
       "      <td>1</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.295195</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.251389</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.155556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36866</th>\n",
       "      <td>55</td>\n",
       "      <td>10</td>\n",
       "      <td>413</td>\n",
       "      <td>0.612745</td>\n",
       "      <td>1</td>\n",
       "      <td>0.784387</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.212963</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.460185</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25067</th>\n",
       "      <td>241</td>\n",
       "      <td>12</td>\n",
       "      <td>384</td>\n",
       "      <td>0.594086</td>\n",
       "      <td>1</td>\n",
       "      <td>0.722892</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415909</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.491667</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14361</th>\n",
       "      <td>455</td>\n",
       "      <td>11</td>\n",
       "      <td>111</td>\n",
       "      <td>0.693694</td>\n",
       "      <td>1</td>\n",
       "      <td>0.757143</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221591</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        timedelta   n_tokens_title   n_tokens_content   n_unique_tokens  \\\n",
       "15427         434               14                559          0.522388   \n",
       "5442          632               10                311          0.537954   \n",
       "36866          55               10                413          0.612745   \n",
       "25067         241               12                384          0.594086   \n",
       "14361         455               11                111          0.693694   \n",
       "\n",
       "        n_non_stop_words   n_non_stop_unique_tokens   num_hrefs  \\\n",
       "15427                  1                   0.680851          21   \n",
       "5442                   1                   0.645833           6   \n",
       "36866                  1                   0.784387          10   \n",
       "25067                  1                   0.722892          15   \n",
       "14361                  1                   0.757143           4   \n",
       "\n",
       "        num_self_hrefs   num_imgs   num_videos              ...                \\\n",
       "15427                6         15            0              ...                 \n",
       "5442                 3          1            0              ...                 \n",
       "36866                1          1            2              ...                 \n",
       "25067                4          9            1              ...                 \n",
       "14361                1          0            1              ...                 \n",
       "\n",
       "        avg_positive_polarity   min_positive_polarity   max_positive_polarity  \\\n",
       "15427                0.391771                0.100000                    1.00   \n",
       "5442                 0.295195                0.050000                    0.70   \n",
       "36866                0.212963                0.033333                    0.50   \n",
       "25067                0.415909                0.136364                    1.00   \n",
       "14361                0.221591                0.136364                    0.25   \n",
       "\n",
       "        avg_negative_polarity   min_negative_polarity   max_negative_polarity  \\\n",
       "15427               -0.377381                    -0.8               -0.050000   \n",
       "5442                -0.251389                    -0.4               -0.155556   \n",
       "36866               -0.460185                    -1.0               -0.100000   \n",
       "25067               -0.491667                    -1.0               -0.200000   \n",
       "14361               -0.100000                    -0.1               -0.100000   \n",
       "\n",
       "        title_subjectivity   title_sentiment_polarity  \\\n",
       "15427             0.560606                   0.068182   \n",
       "5442              0.000000                   0.000000   \n",
       "36866             0.000000                   0.000000   \n",
       "25067             0.357143                   0.000000   \n",
       "14361             0.000000                   0.000000   \n",
       "\n",
       "        abs_title_subjectivity   abs_title_sentiment_polarity  \n",
       "15427                 0.060606                       0.068182  \n",
       "5442                  0.500000                       0.000000  \n",
       "36866                 0.500000                       0.000000  \n",
       "25067                 0.142857                       0.000000  \n",
       "14361                 0.500000                       0.000000  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15427      843\n",
       "5442      3300\n",
       "36866      759\n",
       "25067    21700\n",
       "14361      762\n",
       "Name:  shares, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###diabets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('missing_values/datasets/diabets/pima-indians-diabetes.data', \n",
    "                    names=(['f{0}'.format(i) for i in range(8)] + ['target']), \n",
    "                    na_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#touse\n",
    "data = pd.read_csv('/home/tyamana/missing_values/datasets/diabets/pima-indians-diabetes.data',\n",
    "                    names=(['f{0}'.format(i) for i in range(8)] + ['target']),\n",
    "                    na_values=0)\n",
    "print(data.shape)\n",
    "X = data[data.columns.values[:-1]]\n",
    "Y = data[data.columns.values[-1]]\n",
    "Y = Y.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(230, 58)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('missing_values/datasets/spambase/spambase.data', names=['f{0}'.format(i) for i in range(58)])\n",
    "data = data.sample(frac=0.05, random_state=282)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to use\n",
    "data = pd.read_csv('/home/tyamana/missing_values/datasets/spambase/spambase.data', names=['f{0}'.format(i) for i in range(58)])\n",
    "print(data.shape)\n",
    "X = data[data.columns.values[:-1]]\n",
    "Y = data[data.columns.values[-1]]\n",
    "setNanValuesToDataframe(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###defaultCreditCard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def objectToGoodType(df):\n",
    "    new_df = pd.DataFrame()\n",
    "    for column in df.columns:\n",
    "        new_df[column] = pd.Series([df[column].loc[i] for i in df.index], index=df.index)\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_excel('missing_values/datasets/defaultCreditCard/train.xls')\n",
    "data = copy(raw_data[1:])\n",
    "data.columns = raw_data.loc['ID']\n",
    "data = data.sample(frac=0.012, random_state=410)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = data[data.columns.values[:-1]]\n",
    "X = objectToGoodType(X)\n",
    "Y = data[data.columns.values[-1]]\n",
    "Y = pd.Series([Y.loc[i] for i in Y.index], index=Y.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "for kernel in kernels:\n",
    "    clf = SVC(kernel=kernel)\n",
    "    mean_acc = cross_val_score(clf, X, Y, cv=5).mean()\n",
    "    print(mean_acc, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#touse\n",
    "raw_data = pd.read_excel('/home/tyamana/missing_values/datasets/defaultCreditCard/train.xls')\n",
    "data = copy(raw_data[1:])\n",
    "data.columns = raw_data.loc['ID']\n",
    "data = data.sample(frac=0.12, random_state=410)\n",
    "print(data.shape)\n",
    "X = data[data.columns.values[:-1]]\n",
    "X = objectToGoodType(X)\n",
    "Y = data[data.columns.values[-1]]\n",
    "Y = pd.Series([Y.loc[i] for i in Y.index], index=Y.index)\n",
    "setNanValuesToDataframe(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###eeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/tyamana/missing_values/datasets/eeg/train.txt', \n",
    "                   names=(['f{0}'.format(i) for i in range(14)] + ['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "      <th>f13</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4329.23</td>\n",
       "      <td>4009.23</td>\n",
       "      <td>4289.23</td>\n",
       "      <td>4148.21</td>\n",
       "      <td>4350.26</td>\n",
       "      <td>4586.15</td>\n",
       "      <td>4096.92</td>\n",
       "      <td>4641.03</td>\n",
       "      <td>4222.05</td>\n",
       "      <td>4238.46</td>\n",
       "      <td>4211.28</td>\n",
       "      <td>4280.51</td>\n",
       "      <td>4635.90</td>\n",
       "      <td>4393.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4324.62</td>\n",
       "      <td>4004.62</td>\n",
       "      <td>4293.85</td>\n",
       "      <td>4148.72</td>\n",
       "      <td>4342.05</td>\n",
       "      <td>4586.67</td>\n",
       "      <td>4097.44</td>\n",
       "      <td>4638.97</td>\n",
       "      <td>4210.77</td>\n",
       "      <td>4226.67</td>\n",
       "      <td>4207.69</td>\n",
       "      <td>4279.49</td>\n",
       "      <td>4632.82</td>\n",
       "      <td>4384.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4327.69</td>\n",
       "      <td>4006.67</td>\n",
       "      <td>4295.38</td>\n",
       "      <td>4156.41</td>\n",
       "      <td>4336.92</td>\n",
       "      <td>4583.59</td>\n",
       "      <td>4096.92</td>\n",
       "      <td>4630.26</td>\n",
       "      <td>4207.69</td>\n",
       "      <td>4222.05</td>\n",
       "      <td>4206.67</td>\n",
       "      <td>4282.05</td>\n",
       "      <td>4628.72</td>\n",
       "      <td>4389.23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        f0       f1       f2       f3       f4       f5       f6       f7  \\\n",
       "0  4329.23  4009.23  4289.23  4148.21  4350.26  4586.15  4096.92  4641.03   \n",
       "1  4324.62  4004.62  4293.85  4148.72  4342.05  4586.67  4097.44  4638.97   \n",
       "2  4327.69  4006.67  4295.38  4156.41  4336.92  4583.59  4096.92  4630.26   \n",
       "\n",
       "        f8       f9      f10      f11      f12      f13  target  \n",
       "0  4222.05  4238.46  4211.28  4280.51  4635.90  4393.85       0  \n",
       "1  4210.77  4226.67  4207.69  4279.49  4632.82  4384.10       0  \n",
       "2  4207.69  4222.05  4206.67  4282.05  4628.72  4389.23       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4943, 15)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'setNanValuesToDataframe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-182451fd07b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0msetNanValuesToDataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'setNanValuesToDataframe' is not defined"
     ]
    }
   ],
   "source": [
    "#to use\n",
    "data = pd.read_csv('/home/tyamana/missing_values/datasets/eeg/train.txt',\n",
    "                   names=(['f{0}'.format(i) for i in range(14)] + ['target']))\n",
    "data = data.sample(frac=0.33, random_state=410)\n",
    "print(data.shape)\n",
    "X = data[data.columns.values[:-1]]\n",
    "Y = data[data.columns.values[-1]]\n",
    "setNanValuesToDataframe(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###seismic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/tyamana/missing_values/datasets/eeg/train.txt', \n",
    "                   names=(['f{0}'.format(i) for i in range(14)] + ['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to use in pycharm\n",
    "data = pd.read_csv('/home/tyamana/missing_values/datasets/sismic/train.txt',\n",
    "                   names=(['f{0}'.format(i) for i in range(18)] + ['target']))\n",
    "X = data[data.columns.values[:-1]]\n",
    "num_columns, _ = getNumAndCatfeatures(X)\n",
    "X = data[num_columns]\n",
    "Y = data[data.columns.values[-1]]\n",
    "setNanValuesToDataframe(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###banknot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/tyamana/missing_values/datasets/banknot/train.txt',\n",
    "                   names=(['f{0}'.format(i) for i in range(4)] + ['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#to use\n",
    "data = pd.read_csv('/home/tyamana/missing_values/datasets/banknot/train.txt',\n",
    "                   names=(['f{0}'.format(i) for i in range(4)] + ['target']))\n",
    "X = data[data.columns.values[:-1]]\n",
    "Y = data[data.columns.values[-1]]\n",
    "setNanValuesToDataframe(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###wilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>GLCM_pan</th>\n",
       "      <th>Mean_Green</th>\n",
       "      <th>Mean_Red</th>\n",
       "      <th>Mean_NIR</th>\n",
       "      <th>SD_pan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>w</td>\n",
       "      <td>120.362774</td>\n",
       "      <td>205.500000</td>\n",
       "      <td>119.395349</td>\n",
       "      <td>416.581395</td>\n",
       "      <td>20.676318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w</td>\n",
       "      <td>124.739583</td>\n",
       "      <td>202.800000</td>\n",
       "      <td>115.333333</td>\n",
       "      <td>354.333333</td>\n",
       "      <td>16.707151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>w</td>\n",
       "      <td>134.691964</td>\n",
       "      <td>199.285714</td>\n",
       "      <td>116.857143</td>\n",
       "      <td>477.857143</td>\n",
       "      <td>22.496712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>w</td>\n",
       "      <td>127.946309</td>\n",
       "      <td>178.368421</td>\n",
       "      <td>92.368421</td>\n",
       "      <td>278.473684</td>\n",
       "      <td>14.977453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>w</td>\n",
       "      <td>135.431548</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>112.690476</td>\n",
       "      <td>532.952381</td>\n",
       "      <td>17.604193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class    GLCM_pan  Mean_Green    Mean_Red    Mean_NIR     SD_pan\n",
       "0     w  120.362774  205.500000  119.395349  416.581395  20.676318\n",
       "1     w  124.739583  202.800000  115.333333  354.333333  16.707151\n",
       "2     w  134.691964  199.285714  116.857143  477.857143  22.496712\n",
       "3     w  127.946309  178.368421   92.368421  278.473684  14.977453\n",
       "4     w  135.431548  197.000000  112.690476  532.952381  17.604193"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/home/tyamana/missing_values/datasets/wilt/wilt/training.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n    4265\n",
       "w      74\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    30\n",
       "5    30\n",
       "4    30\n",
       "3    30\n",
       "2    30\n",
       "1    30\n",
       "0    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "Y = data['target']\n",
    "Y = LabelEncoder().fit_transform(Y)\n",
    "pd.Series(Y).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/tyamana/missing_values/datasets/segment/train.txt',\n",
    "                   names=(['target'] + ['f{0}'.format(i) for i in range(19)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###clave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/tyamana/missing_values/datasets/clave/train.txt',\n",
    "                   names=(['target'] + ['f{0}'.format(i) for i in range(19)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###occ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Light</th>\n",
       "      <th>CO2</th>\n",
       "      <th>HumidityRatio</th>\n",
       "      <th>Occupancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-02-04 17:51:00</td>\n",
       "      <td>23.18</td>\n",
       "      <td>27.2720</td>\n",
       "      <td>426.0</td>\n",
       "      <td>721.25</td>\n",
       "      <td>0.004793</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-02-04 17:51:59</td>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2675</td>\n",
       "      <td>429.5</td>\n",
       "      <td>714.00</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-02-04 17:53:00</td>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2450</td>\n",
       "      <td>426.0</td>\n",
       "      <td>713.50</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date  Temperature  Humidity  Light     CO2  HumidityRatio  \\\n",
       "1  2015-02-04 17:51:00        23.18   27.2720  426.0  721.25       0.004793   \n",
       "2  2015-02-04 17:51:59        23.15   27.2675  429.5  714.00       0.004783   \n",
       "3  2015-02-04 17:53:00        23.15   27.2450  426.0  713.50       0.004779   \n",
       "\n",
       "   Occupancy  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/home/tyamana/missing_values/datasets/occ/train.txt')\n",
    "data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Temperature', 'Humidity', 'Light', 'CO2', 'HumidityRatio', 'Occupancy']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num, _ = getNumAndCatFeatures(data)\n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#touse\n",
    "data = pd.read_csv('/home/tyamana/missing_values/datasets/occ/train.txt')\n",
    "print(data.shape)\n",
    "X = data[data.columns.values[:-1]]\n",
    "num_columns, _ = getNumAndCatfeatures(X)\n",
    "X = data[num_columns]\n",
    "Y = data[data.columns.values[-1]]\n",
    "setNanValuesToDataframe(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f12</th>\n",
       "      <th>f13</th>\n",
       "      <th>f14</th>\n",
       "      <th>f15</th>\n",
       "      <th>f16</th>\n",
       "      <th>f17</th>\n",
       "      <th>f18</th>\n",
       "      <th>f19</th>\n",
       "      <th>f20</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.23</td>\n",
       "      <td>-1.56</td>\n",
       "      <td>-1.75</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.22</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.21</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.89</td>\n",
       "      <td>...</td>\n",
       "      <td>2.89</td>\n",
       "      <td>7.75</td>\n",
       "      <td>4.59</td>\n",
       "      <td>3.15</td>\n",
       "      <td>5.12</td>\n",
       "      <td>3.32</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.69</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.61</td>\n",
       "      <td>2.08</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.25</td>\n",
       "      <td>5.52</td>\n",
       "      <td>4.55</td>\n",
       "      <td>2.97</td>\n",
       "      <td>2.22</td>\n",
       "      <td>...</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.88</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.78</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>1.29</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.42</td>\n",
       "      <td>3.55</td>\n",
       "      <td>4.94</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.07</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.41</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.62</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2.19</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>1.13</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.37</td>\n",
       "      <td>5.45</td>\n",
       "      <td>5.45</td>\n",
       "      <td>4.84</td>\n",
       "      <td>...</td>\n",
       "      <td>2.58</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.07</td>\n",
       "      <td>-1.43</td>\n",
       "      <td>2.84</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.16</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>2.66</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.69</td>\n",
       "      <td>4.06</td>\n",
       "      <td>5.34</td>\n",
       "      <td>3.53</td>\n",
       "      <td>...</td>\n",
       "      <td>4.30</td>\n",
       "      <td>1.84</td>\n",
       "      <td>1.73</td>\n",
       "      <td>0.21</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0    f1    f2    f3    f4    f5    f6    f7    f8    f9   ...     f12  \\\n",
       "0 -1.23 -1.56 -1.75 -0.28  0.60  2.22  0.85  0.21 -0.20  0.89   ...    2.89   \n",
       "1 -0.69  2.43  0.61  2.08  2.30  3.25  5.52  4.55  2.97  2.22   ...    1.24   \n",
       "2 -0.12 -0.94  1.29  2.59  2.42  3.55  4.94  3.25  1.90  2.07   ...    2.50   \n",
       "3  0.86  0.29  2.19 -0.02  1.13  2.51  2.37  5.45  5.45  4.84   ...    2.58   \n",
       "4  1.16  0.37  0.40 -0.59  2.66  1.00  2.69  4.06  5.34  3.53   ...    4.30   \n",
       "\n",
       "    f13   f14   f15   f16   f17   f18   f19   f20  target  \n",
       "0  7.75  4.59  3.15  5.12  3.32  1.20  0.24 -0.56       2  \n",
       "1  1.89  1.88 -1.34  0.83  1.41  1.78  0.60  2.42       1  \n",
       "2  0.12  1.41  2.78  0.64  0.62 -0.01 -0.79 -0.12       0  \n",
       "3  1.40  1.24  1.41  1.07 -1.43  2.84 -1.18  1.12       1  \n",
       "4  1.84  1.73  0.21 -0.18  0.13 -0.21 -0.80 -0.68       1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/home/tyamana/missing_values/datasets/waves/waveform.data',\n",
    "                   names=(['f{0}'.format(i) for i in range(21)] + ['target']))\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#touse\n",
    "data = pd.read_csv('/home/tyamana/missing_values/datasets/waves/waveform.data',\n",
    "                   names=(['f{0}'.format(i) for i in range(21)] + ['target']))\n",
    "print(data.shape)\n",
    "X = data[data.columns.values[:-1]]\n",
    "Y = data[data.columns.values[-1]]\n",
    "setNanValuesToDataframe(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Датасет с кэгла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame().from_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114321, 132)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1143, 132)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.sample(frac=0.01, random_state=410)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#выделям из данных Х и Y\n",
    "columns = list(data.columns.values)\n",
    "X_columns = columns[1:]\n",
    "y_column = columns[0]\n",
    "X = data[X_columns]\n",
    "Y = data[y_column]\n",
    "\n",
    "num_columns, cat_columns = getNumAndCatfeatures(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data[num_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3808195850518685"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getMissingDataRate(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as lr\n",
    "\n",
    "def logisticRegClassification(X, y, results, method_name):\n",
    "    scaled_X = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    newton_acc = cross_val_score(lr(solver='newton-cg'), scaled_X, y, cv=5).mean()\n",
    "    lbfgs_acc = cross_val_score(lr(solver='lbfgs'), scaled_X, y, cv=5).mean()\n",
    "    liblinear_acc = cross_val_score(lr(solver='liblinear'), scaled_X, y, cv=5).mean()\n",
    "    sag_acc = cross_val_score(lr(solver='sag'), scaled_X, y, cv=5).mean()\n",
    "    \n",
    "    acc_map = {newton_acc: 'newton-cg', lbfgs_acc: 'lbfgs', liblinear_acc: 'liblinear', sag_acc: 'sag'}\n",
    "    max_acc = max(newton_acc, lbfgs_acc, liblinear_acc, sag_acc)\n",
    "    \n",
    "    results[method_name] = (max_acc, acc_map[max_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#удалим объекты с пропущенными значениями\n",
    "\n",
    "data_deleted = data[num_columns + [y_column]].dropna()\n",
    "X_deleted = data_deleted[data_deleted.columns[:-1]]\n",
    "y_deleted = data_deleted[data_deleted.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.5 s, sys: 201 ms, total: 36.7 s\n",
      "Wall time: 37.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_random, X_mean, X_median, X_mode, X_class_mean, X_class_median, X_class_mode = imputMissingValues(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "devided_features = devide_features_to_classifiable_and_regressiable(X, 10)\n",
    "#devided_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyamana/rep/local/lib/python2.7/site-packages/sklearn/cross_validation.py:516: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=5.\n",
      "  % (min_labels, self.n_folds)), Warning)\n",
      "/home/tyamana/rep/local/lib/python2.7/site-packages/sklearn/cross_validation.py:516: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=5.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.946913093103 3\n",
      "0.672933653846 6\n",
      "0.657553225166 6\n",
      "0.795131533066 7\n",
      "CPU times: user 21.7 s, sys: 19.7 ms, total: 21.8 s\n",
      "Wall time: 21.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyamana/rep/local/lib/python2.7/site-packages/sklearn/cross_validation.py:516: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=5.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#метод ближайших соседей для заполнения пропусков\n",
    "\n",
    "X_knn = X.copy()\n",
    "\n",
    "for column_name in devided_features['class']:\n",
    "    current_X_columns = copy(list(X_knn.columns))\n",
    "    current_X_columns.remove(column_name)\n",
    "    \n",
    "    #обучение\n",
    "    current_y = X_deleted[column_name]\n",
    "    current_X = X_deleted[current_X_columns]\n",
    "    \n",
    "    max_acc = 0\n",
    "    best_neigh_num = 0\n",
    "    epsilon = 0.005\n",
    "    \n",
    "    for neighbors_num in xrange(3, 20):\n",
    "        knn = KNeighborsClassifier(metric = 'manhattan', n_neighbors = neighbors_num)\n",
    "        #knn = KNeighborsClassifier(n_neighbors=neighbors_num)\n",
    "        X_scaled = StandardScaler().fit_transform(current_X)\n",
    "        mean_acc_score = cross_val_score(knn, X_scaled, current_y, cv=5).mean()\n",
    "\n",
    "        if mean_acc_score > max_acc + epsilon:\n",
    "            max_acc = mean_acc_score\n",
    "            best_neigh_num = neighbors_num\n",
    "    \n",
    "    print max_acc, best_neigh_num\n",
    "    \n",
    "    current_X, X_train, y_train, X_test = get_X_and_y_by_column_name(X, current_X_columns, column_name)\n",
    "            \n",
    "    #применение knn\n",
    "    if len(X_test.index) > 0:\n",
    "        knn_for_missing_values = KNeighborsClassifier(metric = 'manhattan', n_neighbors=best_neigh_num)\n",
    "        #knn_for_missing_values = KNeighborsClassifier(n_neighbors=best_neigh_num)\n",
    "        scaler = StandardScaler().fit(current_X)\n",
    "        knn_for_missing_values.fit(scaler.transform(X_train), y_train)\n",
    "        y_test = knn_for_missing_values.predict(scaler.transform(X_test))\n",
    "        X_test_indices = list(X_test.index.values)\n",
    "        counter = 0\n",
    "        for index in X_test_indices:\n",
    "            X_knn.set_value(index, column_name, y_test[counter])\n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#для X_knn соберем y_knn\n",
    "X_knn = X_knn.dropna()\n",
    "y_knn = pd.Series()\n",
    "for index in list(X_knn.index.values):\n",
    "    y_knn.set_value(index, Y.loc[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.948487896253 9\n",
      "0.929785576923 9\n",
      "0.915816650811 9\n",
      "0.95153845018 9\n",
      "CPU times: user 2min 10s, sys: 413 ms, total: 2min 10s\n",
      "Wall time: 2min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#closest_fit\n",
    "X_closest_fit = X.copy()\n",
    "\n",
    "max_min_differences = get_max_min_differences_array_from_data(X_deleted)\n",
    "\n",
    "for column_name in devided_features['class']:\n",
    "    current_X_columns = copy(devided_features['class'])\n",
    "    current_X_columns.remove(column_name)\n",
    "    \n",
    "    #обучение\n",
    "    current_y = X_deleted[column_name]\n",
    "    current_X = X_deleted[current_X_columns]\n",
    "    \n",
    "    max_acc = 0\n",
    "    best_neigh_num = 0\n",
    "    epsilon = 0.005\n",
    "    max_min_differences = get_max_min_differences_array_from_data(X_deleted)\n",
    "\n",
    "    for neighbors_num in xrange(9, 10):\n",
    "        knn = KNeighborsClassifier(n_neighbors=neighbors_num,\n",
    "                                   metric=closest_fit_metric,\n",
    "                                   metric_params={'max_min_differences':max_min_differences})\n",
    "        X_scaled = StandardScaler().fit_transform(current_X)\n",
    "        mean_acc_score = cross_val_score(knn, X_scaled, current_y, cv=5).mean()\n",
    "\n",
    "        if mean_acc_score > max_acc + epsilon:\n",
    "            max_acc = mean_acc_score\n",
    "            best_neigh_num = neighbors_num\n",
    "\n",
    "    print max_acc, best_neigh_num\n",
    "    \n",
    "    current_X, X_train, y_train, X_test = get_X_and_y_by_column_name(X, current_X_columns, column_name)\n",
    "            \n",
    "    max_min_differences = get_max_min_differences_array_from_data(current_X)\n",
    "            \n",
    "    #применение knn\n",
    "    if len(X_test.index) > 0:\n",
    "        knn_for_missing_values = KNeighborsClassifier(n_neighbors=best_neigh_num,\n",
    "                                                      metric=closest_fit_metric,\n",
    "                                                      metric_params={'max_min_differences':max_min_differences})\n",
    "        scaler = StandardScaler().fit(current_X)\n",
    "        knn_for_missing_values.fit(scaler.transform(X_train), y_train)\n",
    "        y_test = knn_for_missing_values.predict(scaler.transform(X_test))\n",
    "        X_test_indices = list(X_test.index.values)\n",
    "        counter = 0\n",
    "        for index in X_test_indices:\n",
    "            X_closest_fit.set_value(index, column_name, y_test[counter])\n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#для X_closest_fit соберем y_closest_fit\n",
    "X_closest_fit = X_closest_fit.dropna()\n",
    "y_closest_fit = pd.Series()\n",
    "for index in list(X_closest_fit.index.values):\n",
    "    y_closest_fit.set_value(index, Y.loc[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#isfinite error\n",
    "%%time\n",
    "from rep.estimators.pybrain import PyBrainClassifier\n",
    "\n",
    "X_pybrain = X.copy()\n",
    "\n",
    "for column_name in devided_features['class']:\n",
    "    current_X_columns = copy(list(X_pybrain.columns))\n",
    "    current_X_columns.remove(column_name)\n",
    "    \n",
    "    current_X, X_train, y_train, X_test = get_X_and_y_by_column_name(X, current_X_columns, column_name)\n",
    "    fitted_y, values_map = fit_y(y_train)\n",
    "    \n",
    "    print 'i'\n",
    "    \n",
    "    pb_for_missing_values = PyBrainClassifier(layers=[10],\n",
    "                                              epochs=10,\n",
    "                                              verbose=False)\n",
    "    pb_for_missing_values.fit(X_train, fitted_y)\n",
    "    y_test_fitted = pb_for_missing_values.predict(X_test)\n",
    "    \n",
    "    y_test = decrypt_y(pd.Series(y_test_fitted), values_map)\n",
    "    X_test_indices = list(X_test.index.values)\n",
    "    counter = 0\n",
    "    for index in X_test_indices:\n",
    "        X_pybrain.set_value(index, column_name, y_test[counter])\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_class_mode, Y_class_mode = dropnaAndAddTarget(X_class_mode, Y, y_column)\n",
    "X_class_mean, Y_class_mean = dropnaAndAddTarget(X_class_mean, Y, y_column)\n",
    "X_class_median, Y_class_median = dropnaAndAddTarget(X_class_median, Y, y_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.74541867769861336, 19) median\n",
      "(0.73842411706121192, 11) random\n",
      "(0.73409021546725262, 17) closest_fit\n",
      "(0.73409021546725262, 17) class_mean\n",
      "(0.73409021546725262, 17) deleted\n",
      "(0.73409021546725262, 17) knn_for_miss_val\n",
      "(0.73409021546725262, 17) class_mode\n",
      "(0.73409021546725262, 17) class_median\n",
      "(0.73404198268597254, 11) mean\n",
      "CPU times: user 19.2 s, sys: 7.57 ms, total: 19.2 s\n",
      "Wall time: 19.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = {}\n",
    "\n",
    "neighbors(X_deleted, y_deleted, results, 'deleted', 10, 20)\n",
    "neighbors(X_random, Y, results, 'random', 10, 20)\n",
    "neighbors(X_mean, Y, results, 'mean', 10, 20)\n",
    "neighbors(X_median, Y, results, 'median', 10, 20)\n",
    "#neighbors(X_mode, Y, results, 'mode', 10, 20)\n",
    "neighbors(X_class_mode, Y_class_mode, results, 'class_mode', 10, 20)\n",
    "neighbors(X_class_mean, Y_class_mean, results, 'class_mean', 10, 20)\n",
    "neighbors(X_class_median, Y_class_median, results, 'class_median', 10, 20)\n",
    "neighbors(X_knn, y_knn, results, 'knn_for_miss_val', 10, 20)\n",
    "neighbors(X_closest_fit, y_closest_fit, results, 'closest_fit', 10, 20)\n",
    "#neighbors(X_pybrain, y_pybrain, results, 'pybrain')\n",
    "\n",
    "sort_and_print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74893894124 mean\n",
      "0.74891212748 random\n",
      "0.741017390638 median\n",
      "0.733943722151 closest_fit\n",
      "0.727742171763 class_median\n",
      "0.719990233779 class_mode\n",
      "0.719965818226 class_mean\n",
      "0.715314655436 deleted\n",
      "0.705743758774 knn_for_miss_val\n",
      "CPU times: user 4min 45s, sys: 287 ms, total: 4min 45s\n",
      "Wall time: 4min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = {}\n",
    "\n",
    "pybrain_classification(X_deleted, y_deleted, results, 'deleted')\n",
    "pybrain_classification(X_random, Y, results, 'random')\n",
    "pybrain_classification(X_mean, Y, results, 'mean')\n",
    "pybrain_classification(X_median, Y, results, 'median')\n",
    "#pybrain_classification(X_mode, Y, results, 'mode')\n",
    "pybrain_classification(X_class_mode, Y_class_mode, results, 'class_mode')\n",
    "pybrain_classification(X_class_mean, Y_class_mean, results, 'class_mean')\n",
    "pybrain_classification(X_class_median, Y_class_median, results, 'class_median')\n",
    "pybrain_classification(X_knn, y_knn, results, 'knn_for_miss_val')\n",
    "pybrain_classification(X_closest_fit, y_closest_fit, results, 'closest_fit')\n",
    "#pybrain_classification(X_pybrain, y_pybrain, results, 'pybrain')\n",
    "\n",
    "sort_and_print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.74797045718122446, 71) closest_fit\n",
      "(0.74654214734786062, 50) class_median\n",
      "(0.74482085088201189, 59) knn_for_miss_val\n",
      "(0.7433192943905268, 53) class_mode\n",
      "(0.74174449124092046, 50) class_mean\n",
      "(0.74172007568821341, 53) deleted\n",
      "(0.74017084195204175, 53) mean\n",
      "(0.73842028652417069, 68) median\n",
      "(0.73754309354171466, 71) random\n",
      "CPU times: user 3min 25s, sys: 283 ms, total: 3min 26s\n",
      "Wall time: 3min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = {}\n",
    "\n",
    "random_forest_classification(X_deleted, y_deleted, results, 'deleted', 50, 80, 3)\n",
    "random_forest_classification(X_random, Y, results, 'random', 50, 80, 3)\n",
    "random_forest_classification(X_mean, Y, results, 'mean', 50, 80, 3)\n",
    "random_forest_classification(X_median, Y, results, 'median', 50, 80, 3)\n",
    "#random_forest_classification(X_mode, Y, results, 'mode', 50, 80)\n",
    "random_forest_classification(X_class_mode, Y_class_mode, results, 'class_mode', 50, 80, 3)\n",
    "random_forest_classification(X_class_mean, Y_class_mean, results, 'class_mean', 50, 80, 3)\n",
    "random_forest_classification(X_class_median, Y_class_median, results, 'class_median', 50, 80, 3)\n",
    "random_forest_classification(X_knn, y_knn, results, 'knn_for_miss_val', 50, 80, 3)\n",
    "random_forest_classification(X_closest_fit, y_closest_fit, results, 'closest_fit', 50, 80, 3)\n",
    "#random_forest_classification(X_pybrain, y_pybrain, results, 'pybrain', 50, 80)\n",
    "    \n",
    "sort_and_print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "results = {}\n",
    "\n",
    "SVMClassification(X_deleted, y_deleted, results, 'deleted')\n",
    "SVMClassification(X_random, Y, results, 'random')\n",
    "SVMClassification(X_mean, Y, results, 'mean')\n",
    "SVMClassification(X_median, Y, results, 'median')\n",
    "#SVMClassification(X_mode, Y, results, 'mode')\n",
    "SVMClassification(X_class_mode, Y_class_mode, results, 'class_mode')\n",
    "SVMClassification(X_class_mean, Y_class_mean, results, 'class_mean')\n",
    "SVMClassification(X_class_median, Y_class_median, results, 'class_median')\n",
    "SVMClassification(X_knn, y_knn, results, 'knn_for_miss_val')\n",
    "SVMClassification(X_closest_fit, y_closest_fit, results, 'closest_fit')\n",
    "#SVMClassification(X_pybrain, y_pybrain, results, 'pybrain')\n",
    "\n",
    "sort_and_print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.73140657320156288, 'newton-cg') random\n",
      "(0.72702826936336473, 'liblinear') median\n",
      "(0.72701677775224083, 'sag') mean\n",
      "(0.70261856802783362, 'sag') closest_fit\n",
      "(0.70261856802783362, 'sag') class_mean\n",
      "(0.70261856802783362, 'sag') deleted\n",
      "(0.70261856802783362, 'sag') knn_for_miss_val\n",
      "(0.70261856802783362, 'sag') class_mode\n",
      "(0.70261856802783362, 'sag') class_median\n",
      "CPU times: user 14.7 s, sys: 27.9 ms, total: 14.7 s\n",
      "Wall time: 14.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyamana/rep/local/lib/python2.7/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = {}\n",
    "\n",
    "logisticRegClassification(X_deleted, y_deleted, results, 'deleted')\n",
    "logisticRegClassification(X_random, Y, results, 'random')\n",
    "logisticRegClassification(X_mean, Y, results, 'mean')\n",
    "logisticRegClassification(X_median, Y, results, 'median')\n",
    "#logisticRegClassification(X_mode, Y, results, 'mode')\n",
    "logisticRegClassification(X_class_mode, Y_class_mode, results, 'class_mode')\n",
    "logisticRegClassification(X_class_mean, Y_class_mean, results, 'class_mean')\n",
    "logisticRegClassification(X_class_median, Y_class_median, results, 'class_median')\n",
    "logisticRegClassification(X_knn, y_knn, results, 'knn_for_miss_val')\n",
    "logisticRegClassification(X_closest_fit, y_closest_fit, results, 'closest_fit')\n",
    "#logisticRegClassification(X_pybrain, y_pybrain, resul ts, 'pybrain')\n",
    "    \n",
    "sort_and_print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.63166704972 median\n",
      "0.630793687275 mean\n",
      "0.615931203555 random\n",
      "0.57632912165 closest_fit\n",
      "0.57632912165 class_mean\n",
      "0.57632912165 deleted\n",
      "0.57632912165 knn_for_miss_val\n",
      "0.57632912165 class_mode\n",
      "0.57632912165 class_median\n",
      "CPU times: user 301 ms, sys: 0 ns, total: 301 ms\n",
      "Wall time: 300 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = {}\n",
    "\n",
    "NBClassification(X_deleted, y_deleted, results, 'deleted')\n",
    "NBClassification(X_random, Y, results, 'random')\n",
    "NBClassification(X_mean, Y, results, 'mean')\n",
    "NBClassification(X_median, Y, results, 'median')\n",
    "#NBClassification(X_mode, Y, results, 'mode')\n",
    "NBClassification(X_class_mode, Y_class_mode, results, 'class_mode')\n",
    "NBClassification(X_class_mean, Y_class_mean, results, 'class_mean')\n",
    "NBClassification(X_class_median, Y_class_median, results, 'class_median')\n",
    "NBClassification(X_knn, y_knn, results, 'knn_for_miss_val')\n",
    "NBClassification(X_closest_fit, y_closest_fit, results, 'closest_fit')\n",
    "#NBClassification(X_pybrain, y_pybrain, results, 'pybrain')\n",
    "\n",
    "#results['raw data'] = cross_val_score(GaussianNB(), X, Y, cv=5).mean()\n",
    "    \n",
    "sort_and_print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Датасет бэндс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Solvent_pct</th>\n",
       "      <th>Esa_voltage</th>\n",
       "      <th>ESA_amperage</th>\n",
       "      <th>Wax</th>\n",
       "      <th>Hardener</th>\n",
       "      <th>Roller_durometer</th>\n",
       "      <th>Density</th>\n",
       "      <th>Anode_ratio</th>\n",
       "      <th>Chrome_content</th>\n",
       "      <th>Band_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34</td>\n",
       "      <td>40</td>\n",
       "      <td>105.00</td>\n",
       "      <td>100</td>\n",
       "      <td>band</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>34</td>\n",
       "      <td>40</td>\n",
       "      <td>105.00</td>\n",
       "      <td>100</td>\n",
       "      <td>noband</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>103.87</td>\n",
       "      <td>100</td>\n",
       "      <td>noband</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>108.06</td>\n",
       "      <td>100</td>\n",
       "      <td>noband</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>106.67</td>\n",
       "      <td>100</td>\n",
       "      <td>noband</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>103.87</td>\n",
       "      <td>100</td>\n",
       "      <td>noband</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>37.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>106.67</td>\n",
       "      <td>100</td>\n",
       "      <td>noband</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>106.67</td>\n",
       "      <td>100</td>\n",
       "      <td>noband</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>39.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>103.22</td>\n",
       "      <td>100</td>\n",
       "      <td>band</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>31.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38</td>\n",
       "      <td>40</td>\n",
       "      <td>106.66</td>\n",
       "      <td>100</td>\n",
       "      <td>noband</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Solvent_pct  Esa_voltage  ESA_amperage  Wax  Hardener  Roller_durometer  \\\n",
       "0         36.4          0.0             0  2.5       1.0                34   \n",
       "1         38.5          0.0             0  2.5       0.7                34   \n",
       "2         39.8          0.0             0  2.8       0.9                40   \n",
       "3         38.8          0.0             0  2.5       1.3                40   \n",
       "4         42.5          5.0             0  2.3       0.6                35   \n",
       "5         37.6          5.0             0  2.5       0.8                40   \n",
       "6         37.5          6.0             0  2.5       0.6                30   \n",
       "7         37.5          6.0             0  2.5       1.1                30   \n",
       "8         39.8          1.5             0  3.0       1.0                40   \n",
       "9         31.8          0.0             0  3.0       1.0                38   \n",
       "\n",
       "   Density  Anode_ratio  Chrome_content Band_type  \n",
       "0       40       105.00             100      band  \n",
       "1       40       105.00             100    noband  \n",
       "2       40       103.87             100    noband  \n",
       "3       40       108.06             100    noband  \n",
       "4       40       106.67             100    noband  \n",
       "5       40       103.87             100    noband  \n",
       "6       40       106.67             100    noband  \n",
       "7       40       106.67             100    noband  \n",
       "8       40       103.22             100      band  \n",
       "9       40       106.66             100    noband  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_data('bands.dat')\n",
    "data[data.columns[-10:]][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Proof_cut', u'Viscosity', u'Caliper', u'Ink_temperature', u'Humifity',\n",
       "       u'Roughness', u'Blade_pressure', u'Varnish_pct', u'Press_speed',\n",
       "       u'Ink_pct', u'Solvent_pct', u'Esa_voltage', u'ESA_amperage', u'Wax',\n",
       "       u'Hardener', u'Roller_durometer', u'Density', u'Anode_ratio',\n",
       "       u'Chrome_content', u'Band_type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#заменим 'band' на 1\n",
    "y_changed = pd.Series()\n",
    "for index in data.index.values:\n",
    "    if data['Band_type'].loc[index] == 'band':\n",
    "        y_changed.set_value(index, np.int64(1))\n",
    "    else:\n",
    "        y_changed.set_value(index, np.int64(0))\n",
    "        \n",
    "data['Band_type'] = y_changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#выделям из данных Х и Y\n",
    "columns = list(data.columns.values)\n",
    "X_columns = columns[:-1]\n",
    "y_column = columns[-1]\n",
    "X = data[X_columns]\n",
    "Y = data[y_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ink_pct</th>\n",
       "      <th>Solvent_pct</th>\n",
       "      <th>Esa_voltage</th>\n",
       "      <th>ESA_amperage</th>\n",
       "      <th>Wax</th>\n",
       "      <th>Hardener</th>\n",
       "      <th>Roller_durometer</th>\n",
       "      <th>Density</th>\n",
       "      <th>Anode_ratio</th>\n",
       "      <th>Chrome_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50.5</td>\n",
       "      <td>36.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34</td>\n",
       "      <td>40</td>\n",
       "      <td>105.00</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.9</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>34</td>\n",
       "      <td>40</td>\n",
       "      <td>105.00</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55.6</td>\n",
       "      <td>38.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>108.06</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57.5</td>\n",
       "      <td>42.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>106.67</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>53.8</td>\n",
       "      <td>37.6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>103.87</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ink_pct  Solvent_pct  Esa_voltage  ESA_amperage  Wax  Hardener  \\\n",
       "0     50.5         36.4            0             0  2.5       1.0   \n",
       "1     54.9         38.5            0             0  2.5       0.7   \n",
       "3     55.6         38.8            0             0  2.5       1.3   \n",
       "4     57.5         42.5            5             0  2.3       0.6   \n",
       "5     53.8         37.6            5             0  2.5       0.8   \n",
       "\n",
       "   Roller_durometer  Density  Anode_ratio  Chrome_content  \n",
       "0                34       40       105.00             100  \n",
       "1                34       40       105.00             100  \n",
       "3                40       40       108.06             100  \n",
       "4                35       40       106.67             100  \n",
       "5                40       40       103.87             100  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#удалим объекты с пропущенными значениями\n",
    "\n",
    "data_deleted = data.dropna()\n",
    "X_deleted = data_deleted[columns[:-1]]\n",
    "y_deleted = data_deleted[columns[-1]]\n",
    "X_deleted[X_deleted.columns[-10:]][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_random, X_mean, X_median, X_mode, X_class_mean, X_class_median, X_class_mode = imputMissingValues(X, Y, X_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class': ['ESA_amperage', 'Density', 'Chrome_content'],\n",
       " 'regr': ['Proof_cut',\n",
       "  'Viscosity',\n",
       "  'Caliper',\n",
       "  'Ink_temperature',\n",
       "  'Humifity',\n",
       "  'Roughness',\n",
       "  'Blade_pressure',\n",
       "  'Varnish_pct',\n",
       "  'Press_speed',\n",
       "  'Ink_pct',\n",
       "  'Solvent_pct',\n",
       "  'Esa_voltage',\n",
       "  'Wax',\n",
       "  'Hardener',\n",
       "  'Roller_durometer',\n",
       "  'Anode_ratio']}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devided_featres = devide_features_to_classifiable_and_regressiable(X, 10)\n",
    "devided_featres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.994666666667 3\n",
      "0.807692970112 5\n",
      "0.964382533218 3\n",
      "CPU times: user 5.57 s, sys: 4 ms, total: 5.58 s\n",
      "Wall time: 5.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#метод ближайших соседей\n",
    "#для начала пойдем самым простым путем - для обучения воспользуемся только полностью заполненными объектами\n",
    "\n",
    "X_knn = X.copy()\n",
    "\n",
    "for column_name in devided_featres['class']:\n",
    "    current_X_columns = copy(X_columns)\n",
    "    current_X_columns.remove(column_name)\n",
    "    \n",
    "    #обучение\n",
    "    current_y = X_deleted[column_name]\n",
    "    current_X = X_deleted[current_X_columns]\n",
    "    \n",
    "    values_map = {}\n",
    "    if column_name == 'ESA_amperage':\n",
    "        current_y, values_map = fit_y(current_y)\n",
    "    \n",
    "    max_acc = 0\n",
    "    best_neigh_num = 0\n",
    "    epsilon = 0.005\n",
    "\n",
    "    for neighbors_num in xrange(3, 20):\n",
    "        knn = KNeighborsClassifier(metric = 'manhattan', n_neighbors = neighbors_num)\n",
    "        #knn = KNeighborsClassifier(n_neighbors=neighbors_num)\n",
    "        X_scaled = StandardScaler().fit_transform(current_X)\n",
    "        mean_acc_score = cross_val_score(knn, X_scaled, current_y, cv=5).mean()\n",
    "\n",
    "        if mean_acc_score > max_acc + epsilon:\n",
    "            max_acc = mean_acc_score\n",
    "            best_neigh_num = neighbors_num\n",
    "\n",
    "    print max_acc, best_neigh_num\n",
    "    \n",
    "    current_X, X_train, y_train, X_test = get_X_and_y_by_column_name(X, current_X_columns, column_name)\n",
    "    \n",
    "    values_map = {}\n",
    "    if column_name == 'ESA_amperage':\n",
    "        y_train, values_map = fit_y(y_train)\n",
    "        \n",
    "    #применение knn\n",
    "    if len(X_test.index) > 0:\n",
    "        knn_for_missing_values = KNeighborsClassifier(metric = 'manhattan', n_neighbors=best_neigh_num)\n",
    "        #knn_for_missing_values = KNeighborsClassifier(n_neighbors=best_neigh_num)\n",
    "        \n",
    "        scaler = StandardScaler().fit(current_X)\n",
    "        \n",
    "        knn_for_missing_values.fit(scaler.transform(X_train), y_train)\n",
    "        \n",
    "        y_test = knn_for_missing_values.predict(scaler.transform(X_test))\n",
    "        if column_name == 'ESA_amperage':\n",
    "            y_test = decrypt_y(y_test, values_map)\n",
    "        \n",
    "        X_test_indices = list(X_test.index.values)\n",
    "        counter = 0\n",
    "        for index in X_test_indices:\n",
    "            X_knn.set_value(index, column_name, y_test[counter])\n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#для X_knn соберем y_knn\n",
    "X_knn = X_knn.dropna()\n",
    "y_knn = pd.Series()\n",
    "for index in list(X_knn.index.values):\n",
    "    y_knn.set_value(index, Y.loc[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###Closest_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.994666666667 9\n",
      "0.8007048897 9\n",
      "0.96167880209 9\n",
      "CPU times: user 11.5 s, sys: 36.1 ms, total: 11.5 s\n",
      "Wall time: 11.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#closest_fit\n",
    "X_closest_fit = X.copy()\n",
    "\n",
    "max_min_differences = get_max_min_differences_array_from_data(X_deleted)\n",
    "\n",
    "for column_name in devided_featres['class']:\n",
    "    current_X_columns = copy(devided_featres['class'])\n",
    "    current_X_columns.remove(column_name)\n",
    "    \n",
    "    #обучение\n",
    "    current_y = X_deleted[column_name]\n",
    "    current_X = X_deleted[current_X_columns]\n",
    "    \n",
    "    values_map = {}\n",
    "    if column_name == 'ESA_amperage':\n",
    "        current_y, values_map = fit_y(current_y)\n",
    "    \n",
    "    max_acc = 0\n",
    "    best_neigh_num = 0\n",
    "    epsilon = 0.005\n",
    "    max_min_differences = get_max_min_differences_array_from_data(X_deleted)\n",
    "\n",
    "    for neighbors_num in xrange(9, 10):\n",
    "        knn = KNeighborsClassifier(n_neighbors=neighbors_num,\n",
    "                                   metric=closest_fit_metric,\n",
    "                                   metric_params={'max_min_differences':max_min_differences})\n",
    "        X_scaled = StandardScaler().fit_transform(current_X)\n",
    "        mean_acc_score = cross_val_score(knn, X_scaled, current_y, cv=5).mean()\n",
    "\n",
    "        if mean_acc_score > max_acc + epsilon:\n",
    "            max_acc = mean_acc_score\n",
    "            best_neigh_num = neighbors_num\n",
    "\n",
    "    print max_acc, best_neigh_num\n",
    "    \n",
    "    current_X, X_train, y_train, X_test = get_X_and_y_by_column_name(X, current_X_columns, column_name)\n",
    "    values_map = {}\n",
    "    if column_name == 'ESA_amperage':\n",
    "        y_train, values_map = fit_y(y_train)\n",
    "            \n",
    "    max_min_differences = get_max_min_differences_array_from_data(current_X)\n",
    "            \n",
    "    #применение knn\n",
    "    if len(X_test.index) > 0:\n",
    "        knn_for_missing_values = KNeighborsClassifier(n_neighbors=best_neigh_num,\n",
    "                                                      metric=closest_fit_metric,\n",
    "                                                      metric_params={'max_min_differences':max_min_differences})\n",
    "        \n",
    "        scaler = StandardScaler().fit(current_X)\n",
    "        \n",
    "        knn_for_missing_values.fit(scaler.transform(X_train), y_train)\n",
    "        \n",
    "        y_test = knn_for_missing_values.predict(scaler.transform(X_test))\n",
    "        if column_name == 'ESA_amperage':\n",
    "            y_test = decrypt_y(pd.Series(y_test), values_map)\n",
    "        \n",
    "        X_test_indices = list(X_test.index.values)\n",
    "        counter = 0\n",
    "        for index in X_test_indices:\n",
    "            X_closest_fit.set_value(index, column_name, y_test[counter])\n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#для X_closest_fit соберем y_closest_fit\n",
    "X_closest_fit = X_closest_fit.dropna()\n",
    "y_closest_fit = pd.Series()\n",
    "for index in list(X_closest_fit.index.values):\n",
    "    y_closest_fit.set_value(index, Y.loc[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###PyBrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Proof_cut', u'Viscosity', u'Caliper', u'Ink_temperature', u'Humifity',\n",
       "       u'Roughness', u'Blade_pressure', u'Varnish_pct', u'Press_speed',\n",
       "       u'Ink_pct', u'Solvent_pct', u'Esa_voltage', u'ESA_amperage', u'Wax',\n",
       "       u'Hardener', u'Roller_durometer', u'Density', u'Anode_ratio',\n",
       "       u'Chrome_content', u'Band_type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_not_object = X.copy()\n",
    "for column in X_not_object.columns:\n",
    "    X_not_object[column] = pd.Series(X_not_object[column].values.astype(type(X_not_object[column].iloc[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###ошибка isfinite\n",
    "from rep.estimators.pybrain import PyBrainClassifier\n",
    "\n",
    "X_pybrain = X_not_object.copy()\n",
    "\n",
    "for column_name in devided_featres['class']:\n",
    "    current_X_columns = copy(X_columns)\n",
    "    current_X_columns.remove(column_name)\n",
    "    \n",
    "    current_X, X_train, y_train, X_test = get_X_and_y_by_column_name(X_not_object, current_X_columns, column_name)\n",
    "    fitted_y, values_map = fit_y(y_train)\n",
    "    \n",
    "    pb_for_missing_values = PyBrainClassifier(layers=[10],\n",
    "                                              epochs=7,\n",
    "                                              verbose=False)\n",
    "    pb_for_missing_values.fit(X_train, fitted_y)\n",
    "    y_test_fitted = pb_for_missing_values.predict(X_test)\n",
    "    \n",
    "    y_test = decrypt_y(pd.Series(y_test_fitted), values_map)\n",
    "    X_test_indices = list(X_test.index.values)\n",
    "    counter = 0\n",
    "    for index in X_test_indices:\n",
    "        X_pybrain.set_value(index, column_name, y_test[counter])\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.65479452054794529, 38) closest_fit\n",
      "(0.65479452054794529, 38) deleted\n",
      "(0.65479452054794529, 38) knn_for_miss_val\n",
      "(0.62966646660378978, 52) class_mode\n",
      "(0.58905941867444045, 50) class_median\n",
      "(0.57570093457943927, 68) class_mean\n",
      "(0.57196261682242988, 34) mode\n",
      "(0.56608076824144726, 76) random\n",
      "(0.56421160936294257, 14) mean\n",
      "(0.55548315184772346, 48) median\n",
      "CPU times: user 35.3 s, sys: 7.86 ms, total: 35.3 s\n",
      "Wall time: 35.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = {}\n",
    "\n",
    "neighbors(X_deleted, y_deleted, results, 'deleted', 10, 100)\n",
    "neighbors(X_random, Y, results, 'random', 10, 100)\n",
    "neighbors(X_mean, Y, results, 'mean', 10, 100)\n",
    "neighbors(X_median, Y, results, 'median', 10, 100)\n",
    "neighbors(X_mode, Y, results, 'mode', 10, 100)\n",
    "neighbors(X_class_mode, Y, results, 'class_mode', 10, 100)\n",
    "neighbors(X_class_mean, Y, results, 'class_mean', 10, 100)\n",
    "neighbors(X_class_median, Y, results, 'class_median', 10, 100)\n",
    "neighbors(X_knn, y_knn, results, 'knn_for_miss_val', 10, 100)\n",
    "neighbors(X_closest_fit, y_closest_fit, results, 'closest_fit', 10, 100)\n",
    "#neighbors(X_pybrain, y_pybrain, results, 'pybrain')\n",
    "\n",
    "sort_and_print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.660273972603 knn_for_miss_val\n",
      "0.624657534247 deleted\n",
      "0.594520547945 closest_fit\n",
      "0.545691503044 random\n",
      "0.536482894624 class_mean\n",
      "0.534270770814 median\n",
      "0.531012603961 class_mode\n",
      "0.530909714482 class_median\n",
      "0.51079482123 mode\n",
      "0.460293235017 mean\n",
      "CPU times: user 2min 51s, sys: 27.7 ms, total: 2min 51s\n",
      "Wall time: 2min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = {}\n",
    "\n",
    "pybrain_classification(X_deleted, y_deleted, results, 'deleted')\n",
    "pybrain_classification(X_random, Y, results, 'random')\n",
    "pybrain_classification(X_mean, Y, results, 'mean')\n",
    "pybrain_classification(X_median, Y, results, 'median')\n",
    "pybrain_classification(X_mode, Y, results, 'mode')\n",
    "pybrain_classification(X_class_mode, Y, results, 'class_mode')\n",
    "pybrain_classification(X_class_mean, Y, results, 'class_mean')\n",
    "pybrain_classification(X_class_median, Y, results, 'class_median')\n",
    "pybrain_classification(X_knn, y_knn, results, 'knn_for_miss_val')\n",
    "pybrain_classification(X_closest_fit, y_closest_fit, results, 'closest_fit')\n",
    "#pybrain_classification(X_pybrain, y_pybrain, results, 'pybrain')\n",
    "\n",
    "sort_and_print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.64784360799108287, 59) class_mode\n",
      "(0.63835616438356158, 74) deleted\n",
      "(0.63835616438356158, 65) knn_for_miss_val\n",
      "(0.6217782731715682, 64) class_median\n",
      "(0.61987481779987985, 70) class_mean\n",
      "(0.61643835616438358, 50) closest_fit\n",
      "(0.61250107176541191, 70) median\n",
      "(0.61059761639372367, 54) mode\n",
      "(0.60876275400840263, 52) mean\n",
      "(0.53260739089428111, 57) random\n",
      "CPU times: user 5min 8s, sys: 846 ms, total: 5min 9s\n",
      "Wall time: 5min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = {}\n",
    "\n",
    "random_forest_classification(X_deleted, y_deleted, results, 'deleted', 50, 80)\n",
    "random_forest_classification(X_random, Y, results, 'random', 50, 80)\n",
    "random_forest_classification(X_mean, Y, results, 'mean', 50, 80)\n",
    "random_forest_classification(X_median, Y, results, 'median', 50, 80)\n",
    "random_forest_classification(X_mode, Y, results, 'mode', 50, 80)\n",
    "random_forest_classification(X_class_mode, Y, results, 'class_mode', 50, 80)\n",
    "random_forest_classification(X_class_mean, Y, results, 'class_mean', 50, 80)\n",
    "random_forest_classification(X_class_median, Y, results, 'class_median', 50, 80)\n",
    "random_forest_classification(X_knn, y_knn, results, 'knn_for_miss_val', 50, 80)\n",
    "random_forest_classification(X_closest_fit, y_closest_fit, results, 'closest_fit', 50, 80)\n",
    "#random_forest_classification(X_pybrain, y_pybrain, results, 'pybrain', 50, 80)\n",
    "    \n",
    "sort_and_print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.63287671232876719, 'SVC') closest_fit\n",
      "(0.63287671232876719, 'SVC') deleted\n",
      "(0.63287671232876719, 'SVC') knn_for_miss_val\n",
      "(0.61250107176541202, 'SVC') class_mode\n",
      "(0.57916488039097991, 'SVC') mode\n",
      "(0.57525508016805271, 'SVC') random\n",
      "(0.57372888622138385, 'SVC') class_median\n",
      "(0.53838634999571289, 'SVC') median\n",
      "(0.53288176283974964, 'SVC') class_mean\n",
      "(0.51419017405470291, 'SVC') mean\n",
      "CPU times: user 4.84 s, sys: 4.01 ms, total: 4.84 s\n",
      "Wall time: 4.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = {}\n",
    "\n",
    "SVMClassification(X_deleted, y_deleted, results, 'deleted')\n",
    "SVMClassification(X_random, Y, results, 'random')\n",
    "SVMClassification(X_mean, Y, results, 'mean')\n",
    "SVMClassification(X_median, Y, results, 'median')\n",
    "SVMClassification(X_mode, Y, results, 'mode')\n",
    "SVMClassification(X_class_mode, Y, results, 'class_mode')\n",
    "SVMClassification(X_class_mean, Y, results, 'class_mean')\n",
    "SVMClassification(X_class_median, Y, results, 'class_median')\n",
    "SVMClassification(X_knn, y_knn, results, 'knn_for_miss_val')\n",
    "SVMClassification(X_closest_fit, y_closest_fit, results, 'closest_fit')\n",
    "#SVMClassification(X_pybrain, y_pybrain, results, 'pybrain')\n",
    "\n",
    "sort_and_print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.56712328767123288, 'sag') closest_fit\n",
      "(0.56712328767123288, 'sag') deleted\n",
      "(0.56712328767123288, 'sag') knn_for_miss_val\n",
      "(0.56632084369373226, 'sag') class_mode\n",
      "(0.54759495841550199, 'lbfgs') class_median\n",
      "(0.54389093715167625, 'sag') random\n",
      "(0.52163251307553793, 'sag') class_mean\n",
      "(0.51816856726399729, 'sag') mode\n",
      "(0.5179284918117123, 'sag') median\n",
      "(0.50117465489153734, 'sag') mean\n",
      "CPU times: user 2.3 s, sys: 0 ns, total: 2.3 s\n",
      "Wall time: 2.32 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyamana/rep/local/lib/python2.7/site-packages/sklearn/linear_model/sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = {}\n",
    "\n",
    "logisticRegClassification(X_deleted, y_deleted, results, 'deleted')\n",
    "logisticRegClassification(X_random, Y, results, 'random')\n",
    "logisticRegClassification(X_mean, Y, results, 'mean')\n",
    "logisticRegClassification(X_median, Y, results, 'median')\n",
    "logisticRegClassification(X_mode, Y, results, 'mode')\n",
    "logisticRegClassification(X_class_mode, Y, results, 'class_mode')\n",
    "logisticRegClassification(X_class_mean, Y, results, 'class_mean')\n",
    "logisticRegClassification(X_class_median, Y, results, 'class_median')\n",
    "logisticRegClassification(X_knn, y_knn, results, 'knn_for_miss_val')\n",
    "logisticRegClassification(X_closest_fit, y_closest_fit, results, 'closest_fit')\n",
    "#logisticRegClassification(X_pybrain, y_pybrain, resul ts, 'pybrain')\n",
    "    \n",
    "sort_and_print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.507296578925 class_mode\n",
      "0.497950784532 mode\n",
      "0.492411900883 class_median\n",
      "0.486804424248 median\n",
      "0.481265540598 random\n",
      "0.481196947612 class_mean\n",
      "0.477527222841 mean\n",
      "0.38904109589 closest_fit\n",
      "0.38904109589 deleted\n",
      "0.38904109589 knn_for_miss_val\n",
      "CPU times: user 136 ms, sys: 4 ms, total: 140 ms\n",
      "Wall time: 141 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = {}\n",
    "\n",
    "NBClassification(X_deleted, y_deleted, results, 'deleted')\n",
    "NBClassification(X_random, Y, results, 'random')\n",
    "NBClassification(X_mean, Y, results, 'mean')\n",
    "NBClassification(X_median, Y, results, 'median')\n",
    "NBClassification(X_mode, Y, results, 'mode')\n",
    "NBClassification(X_class_mode, Y, results, 'class_mode')\n",
    "NBClassification(X_class_mean, Y, results, 'class_mean')\n",
    "NBClassification(X_class_median, Y, results, 'class_median')\n",
    "NBClassification(X_knn, y_knn, results, 'knn_for_miss_val')\n",
    "NBClassification(X_closest_fit, y_closest_fit, results, 'closest_fit')\n",
    "#NBClassification(X_pybrain, y_pybrain, results, 'pybrain')\n",
    "\n",
    "#results['raw data'] = cross_val_score(GaussianNB(), X, Y, cv=5).mean()\n",
    "    \n",
    "sort_and_print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
